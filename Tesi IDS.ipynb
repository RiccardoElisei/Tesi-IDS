{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RiccardoElisei/Tesi-IDS/blob/main/Tesi%20IDS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wmc4uLBtuOV5"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import glob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yswd3EYWuTzi"
      },
      "outputs": [],
      "source": [
        "path = \"drive/MyDrive/MachineLearningCVE/\"\n",
        "files = [file for file in glob.glob(path + \"**/*.csv\", recursive=True)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1EWZcoiZuV5y"
      },
      "outputs": [],
      "source": [
        "[print(f) for f in files]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KKeMzcfpuX_T"
      },
      "outputs": [],
      "source": [
        "dataset = [pd.read_csv(f) for f in files]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g-bT7D_LuaMs"
      },
      "outputs": [],
      "source": [
        "for d in dataset:\n",
        "    print(d.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q_lcmgqSujjE"
      },
      "outputs": [],
      "source": [
        "dataset = pd.concat([d for d in dataset]).drop_duplicates(keep=False)\n",
        "dataset.reset_index(drop=True, inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NHEgvkQsujcF"
      },
      "outputs": [],
      "source": [
        "dataset.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y8HKfJbxujZQ"
      },
      "outputs": [],
      "source": [
        "dataset.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-yhx9bfAujWm"
      },
      "outputs": [],
      "source": [
        "dataset.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ILtDcIhGujTv"
      },
      "outputs": [],
      "source": [
        "dataset.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KQZZ61upujQ3"
      },
      "outputs": [],
      "source": [
        "print(dataset[' Label'].unique())\n",
        "len(dataset[' Label'].unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L5M8U7tWujOA"
      },
      "outputs": [],
      "source": [
        "label_names = dataset[' Label'].unique()\n",
        "\n",
        "import re\n",
        "\n",
        "label_names = [re.sub(\"[^a-zA-Z ]+\", \"\", l) for l in label_names]\n",
        "label_names = [re.sub(\"[\\s\\s]\", '_', l) for l in label_names]\n",
        "label_names = [lab.replace(\"__\", \"_\") for lab in label_names]\n",
        "\n",
        "label_names, len(label_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JY7EyKpjujLJ"
      },
      "outputs": [],
      "source": [
        "labels = dataset[' Label'].unique()\n",
        "\n",
        "for i in range(0,len(label_names)):\n",
        "    dataset[' Label'] = dataset[' Label'].replace({labels[i] : label_names[i]})\n",
        "\n",
        "dataset[' Label'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cW0bnB8KujIS"
      },
      "outputs": [],
      "source": [
        "dataset.isnull().values.any()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oGlJ2nxSujFZ"
      },
      "outputs": [],
      "source": [
        "[col for col in dataset if dataset[col].isnull().values.any()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bIarotRxujCx"
      },
      "outputs": [],
      "source": [
        "dataset['Flow Bytes/s'].isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2dONqw8kui_6"
      },
      "outputs": [],
      "source": [
        "before = dataset.shape\n",
        "dataset.dropna(inplace=True)\n",
        "after = dataset.shape\n",
        "before[0] - after[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0DkLQ2tMui9T"
      },
      "outputs": [],
      "source": [
        "dataset.isnull().any().any()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-h1cxUBGui6K"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kHwKdIOCui3j"
      },
      "outputs": [],
      "source": [
        "labl = dataset[' Label']\n",
        "dataset = dataset.loc[:, dataset.columns != ' Label'].astype('float64')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t0Mx9tcrui08"
      },
      "outputs": [],
      "source": [
        "np.all(np.isfinite(dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0IwOYWXuuix1"
      },
      "outputs": [],
      "source": [
        "nonfinite = [col for col in dataset if not np.all(np.isfinite(dataset[col]))]\n",
        "nonfinite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KrDswaVBuiu8"
      },
      "outputs": [],
      "source": [
        "finite = np.isfinite(dataset['Flow Bytes/s']).sum()\n",
        "\n",
        "dataset.shape[0] - finite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ym3G33yvuimk"
      },
      "outputs": [],
      "source": [
        "finite = np.isfinite(dataset[' Flow Packets/s']).sum()\n",
        "\n",
        "dataset.shape[0] - finite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vxs6IUa-uiX3"
      },
      "outputs": [],
      "source": [
        "dataset = dataset.replace([np.inf, -np.inf], np.nan)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZPj4yOpQvKsq"
      },
      "outputs": [],
      "source": [
        "dataset = dataset.merge(labl, how='outer', left_index=True, right_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XmFufGUMvKp-"
      },
      "outputs": [],
      "source": [
        "dataset.dropna(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SK7DDfhXvKnl"
      },
      "outputs": [],
      "source": [
        "dataset.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6KfaGBkaE2Ea"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pGgZJ7_5E166"
      },
      "outputs": [],
      "source": [
        "np.random.seed(42)\n",
        "rand_perm = np.random.permutation(dataset.shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NernAbP6E1t2"
      },
      "outputs": [],
      "source": [
        "feature_cols = dataset.columns[:-1]\n",
        "\n",
        "dataset_subset = dataset.iloc[rand_perm[:10000],:]\n",
        "dataset_subset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "X = dataset_subset[feature_cols]\n",
        "Y = dataset_subset[' Label']\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Crea un classificatore basato su alberi decisionali (Random Forest)\n",
        "clf = RandomForestClassifier()\n",
        "\n",
        "# Addestra il classificatore sul set di addestramento\n",
        "clf.fit(X_train, Y_train)\n",
        "\n",
        "# Valuta le prestazioni del modello sul set di test\n",
        "Y_pred = clf.predict(X_test)\n",
        "accuracy_rf = accuracy_score(Y_test, Y_pred)\n",
        "\n",
        "# Visualizza l'importanza delle caratteristiche\n",
        "feature_importance = clf.feature_importances_\n",
        "\n",
        "# Crea un DataFrame per organizzare le informazioni\n",
        "feature_df = pd.DataFrame({'Feature': X.columns, 'Importance': feature_importance})\n",
        "\n",
        "# Ordina le feature per importanza\n",
        "feature_df = feature_df.sort_values(by='Importance', ascending=False)\n",
        "\n",
        "weights_rf = {feature: weight for weight, feature in enumerate(feature_df['Feature'], start=1)}\n",
        "\n",
        "# Visualizza il grafico delle feature importance con plt.bar\n",
        "plt.figure(figsize=(15, 8))\n",
        "plt.bar(feature_df['Feature'][:50], feature_df['Importance'][:50], color='skyblue')\n",
        "plt.xlabel('Feature')\n",
        "plt.ylabel('Importance')\n",
        "plt.title('Feature RandomForsetClassifier')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(feature_df.head(50))  # Mostra le prime 50 feature pi첫 importanti\n",
        "\n",
        "print(accuracy_rf)"
      ],
      "metadata": {
        "id": "3NVYr5H665Ae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Seleziona le prime 20 feature dal classificatore RandomForest\n",
        "top_features_rf = feature_df['Feature'][:20].tolist()\n",
        "\n",
        "# Aggiungi il label al set di feature selezionate\n",
        "selected_features_rf = [' Label'] + top_features_rf\n",
        "\n",
        "# Crea un nuovo dataset con solo le prime 20 feature e il label\n",
        "new_dataset_rf = dataset_subset[selected_features_rf]\n",
        "\n",
        "# Visualizza le prime righe del nuovo dataset\n",
        "print(new_dataset_rf.head())"
      ],
      "metadata": {
        "id": "hjdnVrD-8Vzm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.experimental import enable_halving_search_cv\n",
        "from sklearn.model_selection import HalvingGridSearchCV\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "# Separazione delle feature e del label\n",
        "X_rf = new_dataset_rf.drop(' Label', axis=1)  # Rimuovi la colonna del label\n",
        "y_rf = new_dataset_rf[' Label']\n",
        "\n",
        "# Creazione dei set di allenamento e test\n",
        "X_train_rf, X_test_rf, y_train_rf, y_test_rf = train_test_split(X_rf, y_rf, test_size=0.2, random_state=42)\n",
        "\n",
        "# Definizione del modello RandomForest\n",
        "model_rf = RandomForestClassifier()\n",
        "\n",
        "# Definizione della griglia dei parametri da cercare\n",
        "param_grid = {\"max_depth\": [3, None], \"min_samples_split\": [5, 10]}\n",
        "\n",
        "# Ricerca dei parametri migliori con Halving Grid Search CV\n",
        "search = HalvingGridSearchCV(model_rf, param_grid, random_state=42).fit(X_train_rf, y_train_rf)\n",
        "best_rf_params = search.best_params_\n",
        "\n",
        "# Visualizzazione dei parametri migliori\n",
        "print(\"Migliori parametri per RandomForest:\", best_rf_params)\n",
        "\n",
        "# Utilizzo dei migliori parametri per allenare il modello\n",
        "best_model_rf = RandomForestClassifier(**best_rf_params)\n",
        "best_model_rf.fit(X_train_rf, y_train_rf)\n",
        "\n",
        "# Valutazione del modello RandomForest con i migliori parametri\n",
        "predictions_rf_best = best_model_rf.predict(X_test_rf)\n",
        "accuracy_rf_best = accuracy_score(y_test_rf, predictions_rf_best)\n",
        "confusion_matrix_rf_best = confusion_matrix(y_test_rf, predictions_rf_best)\n",
        "\n",
        "# Visualizza i risultati con i migliori parametri\n",
        "print(\"Accuratezza RandomForest RFC con i migliori parametri:\", accuracy_rf_best)\n",
        "print(\"Matrice di confusione RandomForest RFC con i migliori parametri:\\n\", confusion_matrix_rf_best)"
      ],
      "metadata": {
        "id": "C9IRMkARtiFD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Valori della matrice di confusione\n",
        "TN = 1691\n",
        "TP = 0\n",
        "FP = 0\n",
        "FN = 309\n",
        "\n",
        "# Etichette e colori\n",
        "labels = ['True Negative', 'False Positive', 'False Negative', 'True Positive']\n",
        "colors = ['green', 'red', 'orange', 'blue']\n",
        "\n",
        "# Crea il grafico a barre\n",
        "plt.bar(labels, [TN, FP, FN, TP], color=colors)\n",
        "plt.xlabel('Classificazioni')\n",
        "plt.ylabel('Numero di campioni')\n",
        "plt.title('Matrice di Confusione')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fkrOYDVmmWCI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.experimental import enable_halving_search_cv\n",
        "from sklearn.model_selection import HalvingGridSearchCV\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "X_svm_rf = new_dataset_rf.drop(' Label', axis=1)  # Rimuovi la colonna del label\n",
        "y_svm_rf = new_dataset_rf[' Label']\n",
        "\n",
        "# Creazione dei set di allenamento e test\n",
        "X_train_svm_rf, X_test_svm_rf, y_train_svm_rf, y_test_svm_rf = train_test_split(X_svm_rf, y_svm_rf, test_size=0.2, random_state=42)\n",
        "\n",
        "# Definisci il modello\n",
        "model_svm = SVC()\n",
        "\n",
        "# Definisci la griglia degli iperparametri\n",
        "param_grid = {'C': [0.1, 0.5, 1, 2, 5, 10], 'kernel': ['linear', 'rbf', 'sigmoid', 'poly'], 'tol': [1e-3, 1e-2]}\n",
        "\n",
        "# Applica Halving Grid Search CV\n",
        "search_svm = HalvingGridSearchCV(model_svm, param_grid, cv=4, factor=2, max_resources=110, min_resources = 10, aggressive_elimination=False, random_state = 42)\n",
        "search_svm.fit(X_train_svm_rf, y_train_svm_rf)\n",
        "\n",
        "# Ottieni i migliori parametri\n",
        "best_svm_params = search_svm.best_params_\n",
        "\n",
        "# Visualizzazione dei parametri migliori\n",
        "print(\"Migliori parametri per SVM:\", best_svm_params)\n",
        "\n",
        "# Utilizzo dei migliori parametri per allenare il modello\n",
        "best_model_svm_rf = SVC(**best_svm_params)\n",
        "best_model_svm_rf.fit(X_train_svm_rf, y_train_svm_rf)\n",
        "\n",
        "# Valutazione del modello RandomForest con i migliori parametri\n",
        "predictions_svm_rf = best_model_svm_rf.predict(X_test_svm_rf)\n",
        "accuracy_svm_rf = accuracy_score(y_test_svm_rf, predictions_svm_rf)\n",
        "confusion_matrix_svm_rf = confusion_matrix(y_test_svm_rf, predictions_svm_rf)\n",
        "\n",
        "# Visualizza i risultati con i migliori parametri\n",
        "print(\"Accuratezza SVM RFC con i migliori parametri:\", accuracy_svm_rf)\n",
        "print(\"Matrice di confusione SVM RFC con i migliori parametri:\\n\", confusion_matrix_svm_rf)\n"
      ],
      "metadata": {
        "id": "sT50MjHlQKlR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Random Forest Test RFC\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "# Separazione delle feature e del label\n",
        "X_rf = new_dataset_rf.drop(' Label', axis=1)  # Rimuovi la colonna del label\n",
        "y_rf = new_dataset_rf[' Label']\n",
        "\n",
        "\n",
        "# Creazione dei set di allenamento e test\n",
        "X_train_rf, X_test_rf, y_train_rf, y_test_rf = train_test_split(X_rf, y_rf, test_size=0.2, random_state=42)\n",
        "\n",
        "# Allenamento del modello RandomForest\n",
        "model_rf = RandomForestClassifier()\n",
        "model_rf.fit(X_train_rf, y_train_rf)\n",
        "\n",
        "# Valutazione del modello RandomForest\n",
        "predictions_rf = model_rf.predict(X_test_rf)\n",
        "accuracy_rf = accuracy_score(y_test_rf, predictions_rf)\n",
        "confusion_matrix_rf = confusion_matrix(y_test_rf, predictions_rf)\n",
        "\n",
        "# Visualizza i risultati\n",
        "print(\"Accuratezza RandomForest RFC:\", accuracy_rf)\n",
        "print(\"Matrice di confusione RandomForest RFC:\\n\", confusion_matrix_rf)\n"
      ],
      "metadata": {
        "id": "cga0PBcc91-_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Random Forest Test RFC attacchi\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "# Separazione delle feature e del label\n",
        "X_rf = new_dataset_rf.drop(' Label', axis=1)  # Rimuovi la colonna del label\n",
        "y_rf = new_dataset_rf[' Label']\n",
        "\n",
        "\n",
        "# Creazione dei set di allenamento e test\n",
        "X_train_rf, X_test_rf, y_train_rf, y_test_rf = train_test_split(X_rf, y_rf, test_size=0.2, random_state=42)\n",
        "\n",
        "# Allenamento del modello RandomForest\n",
        "model_rf = RandomForestClassifier()\n",
        "model_rf.fit(X_train_rf, y_train_rf)\n",
        "\n",
        "# Valutazione del modello RandomForest\n",
        "predictions_rf = model_rf.predict(X_test_rf)\n",
        "accuracy_rf = accuracy_score(y_test_rf, predictions_rf)\n",
        "confusion_matrix_rf = confusion_matrix(y_test_rf, predictions_rf)\n",
        "\n",
        "# Visualizza i risultati\n",
        "print(\"Accuratezza RandomForest RFC:\", accuracy_rf)\n",
        "print(\"Matrice di confusione RandomForest RFC:\\n\", confusion_matrix_rf)\n",
        "\n",
        "class_report_rf = classification_report(y_test_rf, predictions_rf)\n",
        "print(\"Classification Report - Random Forest RFC:\\n\", class_report_rf)\n",
        "\n",
        "# Estrai le etichette delle classi dal modello\n",
        "class_labels_rf = model_rf.classes_\n",
        "\n",
        "# Per ogni classe, estrai FN e FP dalla matrice di confusione\n",
        "for i, label in enumerate(class_labels_rf):\n",
        "    fn = confusion_matrix_rf[i, :].sum() - confusion_matrix_rf[i, i]  # Somma della riga, escludendo la diagonale\n",
        "    fp = confusion_matrix_rf[:, i].sum() - confusion_matrix_rf[i, i]  # Somma della colonna, escludendo la diagonale\n",
        "\n",
        "    print(f\"\\nClasse: {label}\")\n",
        "    print(f\"False Negative (FN): {fn}\")\n",
        "    print(f\"False Positive (FP): {fp}\")\n"
      ],
      "metadata": {
        "id": "bArD4cS5yTLi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#SVM test RFC attacchi\n",
        "\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "# Separazione delle feature e del label\n",
        "X_svm_rf = new_dataset_rf.drop(' Label', axis=1)  # Rimuovi la colonna del label\n",
        "y_svm_rf = new_dataset_rf[' Label']\n",
        "\n",
        "# Creazione dei set di allenamento e test\n",
        "X_train_svm_rf, X_test_svm_rf, y_train_svm_rf, y_test_svm_rf = train_test_split(X_svm_rf, y_svm_rf, test_size=0.2, random_state=42)\n",
        "\n",
        "# Allenamento del modello SVM\n",
        "model_svm = SVC()\n",
        "model_svm.fit(X_train_svm_rf, y_train_svm_rf)\n",
        "\n",
        "# Valutazione del modello SVM\n",
        "predictions_svm_rf = model_svm.predict(X_test_svm_rf)\n",
        "accuracy_svm_rf = accuracy_score(y_test_svm_rf, predictions_svm_rf)\n",
        "confusion_matrix_svm_rf = confusion_matrix(y_test_svm_rf, predictions_svm_rf)\n",
        "\n",
        "# Ottieni gli iperparametri utilizzati nel modello SVM\n",
        "svm_params = model_svm.get_params()\n",
        "\n",
        "# Visualizza gli iperparametri\n",
        "print(\"Iperparametri utilizzati nel modello SVM:\")\n",
        "for param, value in svm_params.items():\n",
        "    print(f\"{param}: {value}\")\n",
        "\n",
        "# Visualizza i risultati\n",
        "print(\"Accuratezza SVM RFC:\", accuracy_svm_rf)\n",
        "print(\"Matrice di Confusione SVM RFC:\\n\", confusion_matrix_svm_rf)\n",
        "\n",
        "class_report_svm_rf = classification_report(y_test_svm_rf, predictions_svm_rf)\n",
        "print(\"Classification Report - Random Forest RFC:\\n\", class_report_svm_rf)\n",
        "\n",
        "# Estrai le etichette delle classi dal modello\n",
        "class_labels_svm_rf = model_svm.classes_\n",
        "\n",
        "# Per ogni classe, estrai FN e FP dalla matrice di confusione\n",
        "for i, label in enumerate(class_labels_svm_rf):\n",
        "    fn = confusion_matrix_svm_rf[i, :].sum() - confusion_matrix_svm_rf[i, i]  # Somma della riga, escludendo la diagonale\n",
        "    fp = confusion_matrix_svm_rf[:, i].sum() - confusion_matrix_svm_rf[i, i]  # Somma della colonna, escludendo la diagonale\n",
        "\n",
        "    print(f\"\\nClasse: {label}\")\n",
        "    print(f\"False Negative (FN): {fn}\")\n",
        "    print(f\"False Positive (FP): {fp}\")"
      ],
      "metadata": {
        "id": "yV4JRCZNzIU9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#SVM Test RFC\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "# Separazione delle feature e del label\n",
        "X_svm_rf = new_dataset_rf.drop(' Label', axis=1)  # Rimuovi la colonna del label\n",
        "y_svm_rf = new_dataset_rf[' Label']\n",
        "\n",
        "# Creazione dei set di allenamento e test\n",
        "X_train_svm_rf, X_test_svm_rf, y_train_svm_rf, y_test_svm_rf = train_test_split(X_svm_rf, y_svm_rf, test_size=0.2, random_state=42)\n",
        "\n",
        "# Allenamento del modello SVM\n",
        "model_svm = SVC()\n",
        "model_svm.fit(X_train_svm_rf, y_train_svm_rf)\n",
        "\n",
        "# Valutazione del modello SVM\n",
        "predictions_svm_rf = model_svm.predict(X_test_svm_rf)\n",
        "accuracy_svm_rf = accuracy_score(y_test_svm_rf, predictions_svm_rf)\n",
        "confusion_matrix_svm_rf = confusion_matrix(y_test_svm_rf, predictions_svm_rf)\n",
        "\n",
        "# Ottieni gli iperparametri utilizzati nel modello SVM\n",
        "svm_params = model_svm.get_params()\n",
        "\n",
        "# Visualizza gli iperparametri\n",
        "print(\"Iperparametri utilizzati nel modello SVM:\")\n",
        "for param, value in svm_params.items():\n",
        "    print(f\"{param}: {value}\")\n",
        "\n",
        "# Visualizza i risultati\n",
        "print(\"Accuratezza SVM RFC:\", accuracy_svm_rf)\n",
        "print(\"Matrice di Confusione SVM RFC:\\n\", confusion_matrix_svm_rf)\n"
      ],
      "metadata": {
        "id": "AUIwoVgs954Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9TfQehVtBV62"
      },
      "outputs": [],
      "source": [
        "!pip install boruta\n",
        "import pandas as pd\n",
        "from boruta import BorutaPy\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# separiamo le features (X) dal target (Y)\n",
        "X = dataset_subset[feature_cols]\n",
        "Y = dataset_subset[' Label']\n",
        "\n",
        "# Inizializza il classificatore RandomForest\n",
        "rf = RandomForestClassifier(n_jobs=-1, class_weight='balanced', max_depth=5)\n",
        "\n",
        "# Inizializza Boruta\n",
        "boruta_selector = BorutaPy(rf, n_estimators= 50 , verbose=0, max_iter = 100)\n",
        "\n",
        "# Addestra Boruta sul dataset\n",
        "boruta_selector.fit(X.values, Y.values)\n",
        "\n",
        "# Ottieni le caratteristiche selezionate e i loro ranghi\n",
        "selected_features = X.columns[boruta_selector.support_]\n",
        "ranks = boruta_selector.ranking_\n",
        "\n",
        "print(\"Dimensione di selected_features:\", len(selected_features))\n",
        "print(\"Dimensione di boruta_selector.ranking_:\", len(ranks))\n",
        "print(\"Selected Features:\", selected_features[:50])\n",
        "print(\"Ranks:\", boruta_selector.ranking_[:50])\n",
        "\n",
        "# Seleziona solo le colonne corrispondenti alle caratteristiche selezionate\n",
        "X_selected = X[selected_features]\n",
        "\n",
        "# Suddividi il dataset in set di addestramento e set di test\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X_selected, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Inizializza un nuovo classificatore RandomForest\n",
        "rf_selected_features = RandomForestClassifier(n_jobs=-1, class_weight='balanced', max_depth=5)\n",
        "\n",
        "# Addestra il classificatore solo sulle caratteristiche selezionate\n",
        "rf_selected_features.fit(X_train.values, Y_train.values)\n",
        "\n",
        "# Effettua le previsioni sul set di test\n",
        "Y_pred = rf_selected_features.predict(X_test.values)\n",
        "\n",
        "# Calcola l'accuratezza\n",
        "accuracy_boruta = accuracy_score(Y_test, Y_pred)\n",
        "\n",
        "feature_importances = rf_selected_features.feature_importances_\n",
        "\n",
        "feature_weights = {feature: importance for feature, importance in zip(selected_features, feature_importances)}\n",
        "\n",
        "# Ordina le feature in base all'importanza\n",
        "sorted_features = sorted(feature_weights, key=feature_weights.get, reverse=True)\n",
        "\n",
        "# Assegna i pesi in base all'ordine di importanza\n",
        "weights_boruta = {feature: weight for feature, weight in zip(sorted_features, range(1, len(sorted_features) + 1))}\n",
        "\n",
        "# Crea un DataFrame con le caratteristiche e i loro ranghi\n",
        "boruta_results = pd.DataFrame({'Feature': selected_features[:50], 'Rank': boruta_selector.ranking_[:50]})\n",
        "boruta_results = boruta_results.sort_values(by='Rank', ascending=True)\n",
        "\n",
        "# Visualizza i risultati con un grafico a barre\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.bar(range(len(boruta_results)), boruta_results['Rank'], tick_label=boruta_results['Feature'], color = 'skyblue')\n",
        "plt.xticks(rotation=90)\n",
        "plt.title('Boruta')\n",
        "plt.xlabel('Caratteristiche')\n",
        "plt.ylabel('Rango')\n",
        "plt.show()\n",
        "\n",
        "print(boruta_results)\n",
        "\n",
        "print(accuracy_boruta)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Seleziona le prime 20 feature da Boruta\n",
        "top_features_boruta = boruta_results['Feature'][-20:][::-1].tolist()\n",
        "\n",
        "# Aggiungi la colonna del label al set di feature selezionate\n",
        "selected_features_boruta = [' Label'] + top_features_boruta\n",
        "\n",
        "# Crea un nuovo dataset con solo le prime 20 feature e il label\n",
        "new_dataset_boruta = dataset_subset[selected_features_boruta]\n",
        "\n",
        "# Visualizza le prime righe del nuovo dataset\n",
        "print(new_dataset_boruta.head())\n"
      ],
      "metadata": {
        "id": "83Y16f7IIp8R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.experimental import enable_halving_search_cv\n",
        "from sklearn.model_selection import HalvingGridSearchCV\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "X_boruta = new_dataset_boruta.drop(' Label', axis=1)  # Rimuovi la colonna del label\n",
        "y_boruta = new_dataset_boruta[' Label']\n",
        "\n",
        "# Creazione dei set di allenamento e test\n",
        "X_train_boruta, X_test_boruta, y_train_boruta, y_test_boruta = train_test_split(X_boruta, y_boruta, test_size=0.2, random_state=42)\n",
        "\n",
        "# Definizione del modello RandomForest\n",
        "model_boruta = RandomForestClassifier()\n",
        "\n",
        "# Definizione della griglia dei parametri da cercare\n",
        "param_grid = {\"max_depth\": [3, None], \"min_samples_split\": [5, 10]}\n",
        "\n",
        "# Ricerca dei parametri migliori con Halving Grid Search CV\n",
        "search = HalvingGridSearchCV(model_boruta, param_grid, random_state=42).fit(X_train_boruta, y_train_boruta)\n",
        "best_boruta_params = search.best_params_\n",
        "\n",
        "# Visualizzazione dei parametri migliori\n",
        "print(\"Migliori parametri per RandomForestClassifier:\", best_boruta_params)\n",
        "\n",
        "# Utilizzo dei migliori parametri per allenare il modello\n",
        "best_model_boruta = RandomForestClassifier(**best_boruta_params)\n",
        "best_model_boruta.fit(X_train_boruta, y_train_boruta)\n",
        "\n",
        "# Valutazione del modello RandomForest con i migliori parametri\n",
        "predictions_boruta_best = best_model_boruta.predict(X_test_boruta)\n",
        "accuracy_boruta_best = accuracy_score(y_test_boruta, predictions_boruta_best)\n",
        "confusion_matrix_boruta_best = confusion_matrix(y_test_boruta, predictions_boruta_best)\n",
        "\n",
        "# Visualizza i risultati con i migliori parametri\n",
        "print(\"Accuratezza RandomForest Boruta con i migliori parametri:\", accuracy_boruta_best)\n",
        "print(\"Matrice di confusione RandomForest Boruta con i migliori parametri:\\n\", confusion_matrix_boruta_best)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "EKF1bEx8XZ2o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.experimental import enable_halving_search_cv\n",
        "from sklearn.model_selection import HalvingGridSearchCV\n",
        "\n",
        "# Separazione delle feature e del label\n",
        "X_svm_b = new_dataset_boruta.drop(' Label', axis=1)  # Rimuovi la colonna del label\n",
        "y_svm_b = new_dataset_boruta[' Label']\n",
        "\n",
        "# Creazione dei set di allenamento e test\n",
        "X_train_svm_b, X_test_svm_b, y_train_svm_b, y_test_svm_b = train_test_split(X_svm_b, y_svm_b, test_size=0.2, random_state=42)\n",
        "\n",
        "# Definisci il modello\n",
        "model_svm_b = SVC()\n",
        "\n",
        "# Definisci la griglia degli iperparametri\n",
        "param_grid = {'C': [0.1, 0.5, 1, 2, 5, 10], 'kernel': ['linear', 'rbf', 'sigmoid', 'poly'], 'tol': [1e-3, 1e-2]}\n",
        "\n",
        "# Applica Halving Grid Search CV\n",
        "search_svm = HalvingGridSearchCV(model_svm_b, param_grid, cv=5, factor=2, max_resources=110, min_resources=10, aggressive_elimination=False, random_state = 42)\n",
        "search_svm.fit(X_train_svm_b, y_train_svm_b)\n",
        "\n",
        "# Ottieni i migliori parametri\n",
        "best_svm_params = search_svm.best_params_\n",
        "\n",
        "# Visualizzazione dei parametri migliori\n",
        "print(\"Migliori parametri per SVM:\", best_svm_params)\n",
        "\n",
        "# Utilizzo dei migliori parametri per allenare il modello\n",
        "best_model_svm_b = SVC(**best_svm_params)\n",
        "best_model_svm_b.fit(X_train_svm_b, y_train_svm_b)\n",
        "\n",
        "# Valutazione del modello RandomForest con i migliori parametri\n",
        "predictions_svm_b = best_model_svm_b.predict(X_test_svm_b)\n",
        "accuracy_svm_b = accuracy_score(y_test_svm_b, predictions_svm_b)\n",
        "confusion_matrix_svm_b = confusion_matrix(y_test_svm_b, predictions_svm_b)\n",
        "\n",
        "# Visualizza i risultati con i migliori parametri\n",
        "print(\"Accuratezza SVM Boruta con i migliori parametri:\", accuracy_svm_b)\n",
        "print(\"Matrice di confusione SVM Boruta con i migliori parametri:\\n\", confusion_matrix_svm_b)"
      ],
      "metadata": {
        "id": "QjNwT_3SY5ay"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "X_boruta = new_dataset_boruta.drop(' Label', axis=1)  # Rimuovi la colonna del label\n",
        "y_boruta = new_dataset_boruta[' Label']\n",
        "\n",
        "# Creazione dei set di allenamento e test\n",
        "X_train_boruta, X_test_boruta, y_train_boruta, y_test_boruta = train_test_split(X_boruta, y_boruta, test_size=0.2, random_state=42)\n",
        "\n",
        "# Allenamento del modello RandomForest\n",
        "model_boruta = RandomForestClassifier()\n",
        "model_boruta.fit(X_train_boruta, y_train_boruta)\n",
        "\n",
        "# Valutazione del modello RandomForest\n",
        "predictions_boruta = model_boruta.predict(X_test_boruta)\n",
        "accuracy_boruta = accuracy_score(y_test_boruta, predictions_boruta)\n",
        "confusion_matrix_boruta = confusion_matrix(y_test_boruta, predictions_boruta)\n",
        "\n",
        "# Visualizza i risultati\n",
        "print(\"Accuratezza RandomForest Boruta:\", accuracy_boruta)\n",
        "print(\"Matrice di confusione RandomForest Boruta:\\n\", confusion_matrix_boruta)"
      ],
      "metadata": {
        "id": "T37wpOPpKk2v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "X_boruta = new_dataset_boruta.drop(' Label', axis=1)  # Rimuovi la colonna del label\n",
        "y_boruta = new_dataset_boruta[' Label']\n",
        "\n",
        "# Creazione dei set di allenamento e test\n",
        "X_train_boruta, X_test_boruta, y_train_boruta, y_test_boruta = train_test_split(X_boruta, y_boruta, test_size=0.2, random_state=42)\n",
        "\n",
        "# Allenamento del modello RandomForest\n",
        "model_boruta = RandomForestClassifier()\n",
        "model_boruta.fit(X_train_boruta, y_train_boruta)\n",
        "\n",
        "# Valutazione del modello RandomForest\n",
        "predictions_boruta = model_boruta.predict(X_test_boruta)\n",
        "accuracy_boruta = accuracy_score(y_test_boruta, predictions_boruta)\n",
        "confusion_matrix_boruta = confusion_matrix(y_test_boruta, predictions_boruta)\n",
        "\n",
        "# Visualizza i risultati\n",
        "print(\"Accuratezza RandomForest Boruta:\", accuracy_boruta)\n",
        "print(\"Matrice di confusione RandomForest Boruta:\\n\", confusion_matrix_boruta)\n",
        "\n",
        "class_report_b_rf = classification_report(y_test_boruta, predictions_boruta)\n",
        "print(\"Classification Report - Random Forest RFC:\\n\", class_report_b_rf)\n",
        "\n",
        "# Estrai le etichette delle classi dal modello\n",
        "class_labels_b_rf = model_boruta.classes_\n",
        "\n",
        "# Per ogni classe, estrai FN e FP dalla matrice di confusione\n",
        "for i, label in enumerate(class_labels_b_rf):\n",
        "    fn = confusion_matrix_boruta[i, :].sum() - confusion_matrix_boruta[i, i]  # Somma della riga, escludendo la diagonale\n",
        "    fp = confusion_matrix_boruta[:, i].sum() - confusion_matrix_boruta[i, i]  # Somma della colonna, escludendo la diagonale\n",
        "\n",
        "    print(f\"\\nClasse: {label}\")\n",
        "    print(f\"False Negative (FN): {fn}\")\n",
        "    print(f\"False Positive (FP): {fp}\")"
      ],
      "metadata": {
        "id": "StvnAIGA0xub"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "# Separazione delle feature e del label\n",
        "X_svm_b = new_dataset_boruta.drop(' Label', axis=1)  # Rimuovi la colonna del label\n",
        "y_svm_b = new_dataset_boruta[' Label']\n",
        "\n",
        "# Creazione dei set di allenamento e test\n",
        "X_train_svm_b, X_test_svm_b, y_train_svm_b, y_test_svm_b = train_test_split(X_svm_b, y_svm_b, test_size=0.2, random_state=42)\n",
        "\n",
        "# Allenamento del modello SVM\n",
        "model_svm_b = SVC()\n",
        "model_svm_b.fit(X_train_svm_b, y_train_svm_b)\n",
        "\n",
        "# Valutazione del modello SVM\n",
        "predictions_svm_b = model_svm_b.predict(X_test_svm_b)\n",
        "accuracy_svm_b = accuracy_score(y_test_svm_b, predictions_svm_b)\n",
        "confusion_matrix_svm_b = confusion_matrix(y_test_svm_b, predictions_svm_b)\n",
        "\n",
        "# Visualizza i risultati\n",
        "print(\"Accuratezza SVM RFC:\", accuracy_svm_b)\n",
        "print(\"Matrice di Confusione SVM RFC:\\n\", confusion_matrix_svm_b)\n",
        "\n",
        "class_report_svm_b = classification_report(y_test_svm_b, predictions_svm_b)\n",
        "print(\"Classification Report - Random Forest RFC:\\n\", class_report_svm_b)\n",
        "\n",
        "# Estrai le etichette delle classi dal modello\n",
        "class_labels_svm_b = model_svm_b.classes_\n",
        "\n",
        "# Per ogni classe, estrai FN e FP dalla matrice di confusione\n",
        "for i, label in enumerate(class_labels_b_rf):\n",
        "    fn = confusion_matrix_svm_b[i, :].sum() - confusion_matrix_svm_b[i, i]  # Somma della riga, escludendo la diagonale\n",
        "    fp = confusion_matrix_svm_b[:, i].sum() - confusion_matrix_svm_b[i, i]  # Somma della colonna, escludendo la diagonale\n",
        "\n",
        "    print(f\"\\nClasse: {label}\")\n",
        "    print(f\"False Negative (FN): {fn}\")\n",
        "    print(f\"False Positive (FP): {fp}\")"
      ],
      "metadata": {
        "id": "3hUeREpS1oQE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "# Separazione delle feature e del label\n",
        "X_svm_b = new_dataset_boruta.drop(' Label', axis=1)  # Rimuovi la colonna del label\n",
        "y_svm_b = new_dataset_boruta[' Label']\n",
        "\n",
        "# Creazione dei set di allenamento e test\n",
        "X_train_svm_b, X_test_svm_b, y_train_svm_b, y_test_svm_b = train_test_split(X_svm_b, y_svm_b, test_size=0.2, random_state=42)\n",
        "\n",
        "# Allenamento del modello SVM\n",
        "model_svm_b = SVC()\n",
        "model_svm_b.fit(X_train_svm_b, y_train_svm_b)\n",
        "\n",
        "# Valutazione del modello SVM\n",
        "predictions_svm_b = model_svm_b.predict(X_test_svm_b)\n",
        "accuracy_svm_b = accuracy_score(y_test_svm_b, predictions_svm_b)\n",
        "confusion_matrix_svm_b = confusion_matrix(y_test_svm_b, predictions_svm_b)\n",
        "\n",
        "# Visualizza i risultati\n",
        "print(\"Accuratezza SVM RFC:\", accuracy_svm_b)\n",
        "print(\"Matrice di Confusione SVM RFC:\\n\", confusion_matrix_svm_b)"
      ],
      "metadata": {
        "id": "wk8l5kQJMYM-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FrZnXhT-GQ-6"
      },
      "outputs": [],
      "source": [
        "pca = PCA(n_components=50)\n",
        "pca_res = pca.fit_transform(dataset_subset[feature_cols])\n",
        "\n",
        "# Supponendo che i carichi delle variabili siano memorizzati nella variabile 'loadings'\n",
        "loadings = np.abs(pca.components_[0])\n",
        "\n",
        "# Ottieni gli indici delle variabili con i valori assoluti pi첫 alti\n",
        "top_variables_indices = np.argsort(loadings)[::-1]\n",
        "\n",
        "#weights_pca = {column_names[idx]: weight for weight, idx in enumerate(top_variables_indices, start=1)}\n",
        "\n",
        "# Visualizza le prime N variabili pi첫 influenti\n",
        "N = 50  # Puoi impostare questo valore in base a quanto vuoi visualizzare\n",
        "top_variables = top_variables_indices[:N]\n",
        "\n",
        "# Ottieni i nomi delle colonne corrispondenti agli indici delle variabili\n",
        "column_names = dataset_subset.columns\n",
        "\n",
        "# Prepara i dati per il grafico\n",
        "top_variable_names = [column_names[idx] for idx in top_variables]\n",
        "top_variable_loadings = [loadings[idx] for idx in top_variables]\n",
        "\n",
        "weights_pca = {column_names[idx]: weight for weight, idx in enumerate(top_variables_indices, start=1)}\n",
        "\n",
        "# Crea il grafico a barre\n",
        "plt.figure(figsize=(12,8))\n",
        "plt.bar(top_variable_names, top_variable_loadings, color='skyblue')\n",
        "plt.xlabel('Carichi delle Variabili')\n",
        "plt.title('Carichi delle Variabili pi첫 Influenti dopo PCA')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.show()\n",
        "\n",
        "total_variance = np.sum(np.var(dataset_subset, axis=0))\n",
        "explained_variance = np.sum(pca.explained_variance_[:N])\n",
        "accuracy_pca = (explained_variance/total_variance)*100\n",
        "\n",
        "# Stampa i risultati\n",
        "for idx in top_variables:\n",
        "    variable_name = column_names[idx]\n",
        "    print(f\"Variabile: {variable_name}, Carico: {loadings[idx]}\")\n",
        "\n",
        "print(accuracy_pca)\n",
        "\n",
        "data_subset = None"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.experimental import enable_halving_search_cv\n",
        "from sklearn.model_selection import HalvingGridSearchCV\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "# Assume che 'target' sia la colonna target del tuo dataset\n",
        "target = dataset_subset[' Label']\n",
        "X_train_pca, X_test_pca, y_train_pca, y_test_pca = train_test_split(pca_res[:, :20], target, test_size=0.2, random_state=42)\n",
        "\n",
        "# Definizione del modello RandomForest\n",
        "model_pca_rf = RandomForestClassifier()\n",
        "\n",
        "# Definizione della griglia dei parametri da cercare\n",
        "param_grid = {\"max_depth\": [3, None], \"min_samples_split\": [5, 10]}\n",
        "\n",
        "# Ricerca dei parametri migliori con Halving Grid Search CV\n",
        "search = HalvingGridSearchCV(model_pca_rf, param_grid, random_state=42).fit(X_train_pca, y_train_pca)\n",
        "best_pca_params = search.best_params_\n",
        "\n",
        "# Visualizzazione dei parametri migliori\n",
        "print(\"Migliori parametri per RandomForestClassifier:\", best_pca_params)\n",
        "\n",
        "# Utilizzo dei migliori parametri per allenare il modello\n",
        "best_model_pca = RandomForestClassifier(**best_pca_params)\n",
        "best_model_pca.fit(X_train_pca, y_train_pca)\n",
        "\n",
        "# Valutazione del modello RandomForest con i migliori parametri\n",
        "predictions_pca_best = best_model_pca.predict(X_test_pca)\n",
        "accuracy_pca_best = accuracy_score(y_test_pca, predictions_pca_best)\n",
        "confusion_matrix_pca_best = confusion_matrix(y_test_pca, predictions_pca_best)\n",
        "\n",
        "# Visualizza i risultati con i migliori parametri\n",
        "print(\"Accuratezza RandomForest PCA con i migliori parametri:\", accuracy_pca_best)\n",
        "print(\"Matrice di confusione RandomForest PCA con i migliori parametri:\\n\", confusion_matrix_pca_best)"
      ],
      "metadata": {
        "id": "E1NrNWlfaEUR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.experimental import enable_halving_search_cv\n",
        "from sklearn.model_selection import HalvingGridSearchCV\n",
        "\n",
        "# Assume che 'target' sia la colonna target del tuo dataset\n",
        "target = dataset_subset[' Label']\n",
        "X_train_svm_pca, X_test_svm_pca, y_train_svm_pca, y_test_svm_pca = train_test_split(pca_res[:, :10], target, test_size=0.2, random_state=42)\n",
        "\n",
        "# Support Vector Machine (SVM)\n",
        "svm_model_pca = SVC()\n",
        "\n",
        "# Definisci la griglia degli iperparametri\n",
        "param_grid = {'C': [0.1, 0.5, 1, 2, 5, 10], 'kernel': ['linear', 'rbf', 'sigmoid', 'poly'], 'tol': [1e-3, 1e-2]}\n",
        "\n",
        "# Applica Halving Grid Search CV\n",
        "search_svm = HalvingGridSearchCV(svm_model_pca, param_grid, cv=5, factor=2, max_resources=110, min_resources=10, aggressive_elimination=False, random_state = 42)\n",
        "search_svm.fit(X_train_svm_pca, y_train_svm_pca)\n",
        "\n",
        "# Ottieni i migliori parametri\n",
        "best_svm_params = search_svm.best_params_\n",
        "\n",
        "# Visualizzazione dei parametri migliori\n",
        "print(\"Migliori parametri per SVM:\", best_svm_params)\n",
        "\n",
        "# Utilizzo dei migliori parametri per allenare il modello\n",
        "best_model_svm_pca = SVC(**best_svm_params)\n",
        "best_model_svm_pca.fit(X_train_svm_pca, y_train_svm_pca)\n",
        "\n",
        "# Valutazione del modello RandomForest con i migliori parametri\n",
        "predictions_svm_pca = best_model_svm_pca.predict(X_test_svm_pca)\n",
        "accuracy_svm_pca = accuracy_score(y_test_svm_pca, predictions_svm_pca)\n",
        "confusion_matrix_svm_pca = confusion_matrix(y_test_svm_pca, predictions_svm_pca)\n",
        "\n",
        "# Visualizza i risultati con i migliori parametri\n",
        "print(\"Accuratezza SVM PCA con i migliori parametri:\", accuracy_svm_pca)\n",
        "print(\"Matrice di confusione SVM PCA con i migliori parametri:\\n\", confusion_matrix_svm_pca)"
      ],
      "metadata": {
        "id": "UWC9sC5pbEi4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "# Assume che 'target' sia la colonna target del tuo dataset\n",
        "target = dataset_subset[' Label']\n",
        "X_train_pca, X_test_pca, y_train_pca, y_test_pca = train_test_split(pca_res[:, :30], target, test_size=0.2, random_state=42)\n",
        "\n",
        "rf_model_pca = RandomForestClassifier()\n",
        "rf_model_pca.fit(X_train_pca, y_train_pca)\n",
        "rf_predictions_pca = rf_model_pca.predict(X_test_pca)\n",
        "\n",
        "# Valutazione del modello RF\n",
        "rf_accuracy_pca = accuracy_score(y_test_pca, rf_predictions_pca)\n",
        "print(\"Accuracy Random Forest:\", rf_accuracy_pca)\n",
        "\n",
        "# Matrice di confusione RF\n",
        "rf_conf_matrix_pca = confusion_matrix(y_test_pca, rf_predictions_pca)\n",
        "print(\"\\nMatrice di Confusione Random Forest:\")\n",
        "print(rf_conf_matrix_pca)\n"
      ],
      "metadata": {
        "id": "0V7-EriAOq7l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.experimental import enable_halving_search_cv\n",
        "from sklearn.model_selection import HalvingGridSearchCV\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "# Assume che 'target' sia la colonna target del tuo dataset\n",
        "target = dataset_subset[' Label']\n",
        "X_train_pca, X_test_pca, y_train_pca, y_test_pca = train_test_split(pca_res[:, :20], target, test_size=0.2, random_state=42)\n",
        "\n",
        "# Definizione del modello RandomForest\n",
        "model_pca_rf = RandomForestClassifier()\n",
        "\n",
        "# Definizione della griglia dei parametri da cercare\n",
        "param_grid = {\"max_depth\": [3, None], \"min_samples_split\": [5, 10]}\n",
        "\n",
        "# Ricerca dei parametri migliori con Halving Grid Search CV\n",
        "search = HalvingGridSearchCV(model_pca_rf, param_grid, random_state=42).fit(X_train_pca, y_train_pca)\n",
        "best_pca_params = search.best_params_\n",
        "\n",
        "# Visualizzazione dei parametri migliori\n",
        "print(\"Migliori parametri per RandomForestClassifier:\", best_pca_params)\n",
        "\n",
        "# Utilizzo dei migliori parametri per allenare il modello\n",
        "best_model_pca = RandomForestClassifier(**best_pca_params)\n",
        "best_model_pca.fit(X_train_pca, y_train_pca)\n",
        "\n",
        "# Valutazione del modello RandomForest con i migliori parametri\n",
        "predictions_pca_best = best_model_pca.predict(X_test_pca)\n",
        "accuracy_pca_best = accuracy_score(y_test_pca, predictions_pca_best)\n",
        "confusion_matrix_pca_best = confusion_matrix(y_test_pca, predictions_pca_best)\n",
        "\n",
        "# Visualizza i risultati con i migliori parametri\n",
        "print(\"Accuratezza RandomForest PCA con i migliori parametri:\", accuracy_pca_best)\n",
        "print(\"Matrice di confusione RandomForest PCA con i migliori parametri:\\n\", confusion_matrix_pca_best)\n",
        "\n",
        "class_report_pca = classification_report(y_test_pca, predictions_pca_best)\n",
        "print(\"Classification Report - Random Forest RFC:\\n\", class_report_pca)\n",
        "\n",
        "# Estrai le etichette delle classi dal modello\n",
        "class_labels_pca = best_model_pca.classes_\n",
        "\n",
        "# Per ogni classe, estrai FN e FP dalla matrice di confusione\n",
        "for i, label in enumerate(class_labels_pca):\n",
        "    fn = confusion_matrix_pca_best[i, :].sum() - confusion_matrix_pca_best[i, i]  # Somma della riga, escludendo la diagonale\n",
        "    fp = confusion_matrix_pca_best[:, i].sum() - confusion_matrix_pca_best[i, i]  # Somma della colonna, escludendo la diagonale\n",
        "\n",
        "    print(f\"\\nClasse: {label}\")\n",
        "    print(f\"False Negative (FN): {fn}\")\n",
        "    print(f\"False Positive (FP): {fp}\")"
      ],
      "metadata": {
        "id": "pbwx0SfR2noH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.experimental import enable_halving_search_cv\n",
        "from sklearn.model_selection import HalvingGridSearchCV\n",
        "\n",
        "# Assume che 'target' sia la colonna target del tuo dataset\n",
        "target = dataset_subset[' Label']\n",
        "X_train_svm_pca, X_test_svm_pca, y_train_svm_pca, y_test_svm_pca = train_test_split(pca_res[:, :10], target, test_size=0.2, random_state=42)\n",
        "\n",
        "# Support Vector Machine (SVM)\n",
        "svm_model_pca = SVC()\n",
        "\n",
        "# Definisci la griglia degli iperparametri\n",
        "param_grid = {'C': [0.1, 0.5, 1, 2, 5, 10], 'kernel': ['linear', 'rbf', 'sigmoid', 'poly'], 'tol': [1e-3, 1e-2]}\n",
        "\n",
        "# Applica Halving Grid Search CV\n",
        "search_svm = HalvingGridSearchCV(svm_model_pca, param_grid, cv=5, factor=2, max_resources=110, min_resources=10, aggressive_elimination=False, random_state = 42)\n",
        "search_svm.fit(X_train_svm_pca, y_train_svm_pca)\n",
        "\n",
        "# Ottieni i migliori parametri\n",
        "best_svm_params = search_svm.best_params_\n",
        "\n",
        "# Visualizzazione dei parametri migliori\n",
        "print(\"Migliori parametri per SVM:\", best_svm_params)\n",
        "\n",
        "# Utilizzo dei migliori parametri per allenare il modello\n",
        "best_model_svm_pca = SVC(**best_svm_params)\n",
        "best_model_svm_pca.fit(X_train_svm_pca, y_train_svm_pca)\n",
        "\n",
        "# Valutazione del modello RandomForest con i migliori parametri\n",
        "predictions_svm_pca = best_model_svm_pca.predict(X_test_svm_pca)\n",
        "accuracy_svm_pca = accuracy_score(y_test_svm_pca, predictions_svm_pca)\n",
        "confusion_matrix_svm_pca = confusion_matrix(y_test_svm_pca, predictions_svm_pca)\n",
        "\n",
        "# Visualizza i risultati con i migliori parametri\n",
        "print(\"Accuratezza SVM PCA con i migliori parametri:\", accuracy_svm_pca)\n",
        "print(\"Matrice di confusione SVM PCA con i migliori parametri:\\n\", confusion_matrix_svm_pca)\n",
        "\n",
        "class_report_svm_pca = classification_report(y_test_svm_pca, predictions_svm_pca)\n",
        "print(\"Classification Report - Random Forest RFC:\\n\", class_report_svm_pca)\n",
        "\n",
        "# Estrai le etichette delle classi dal modello\n",
        "class_labels_svm_pca = best_model_svm_pca.classes_\n",
        "\n",
        "# Per ogni classe, estrai FN e FP dalla matrice di confusione\n",
        "for i, label in enumerate(class_labels_svm_pca):\n",
        "    fn = confusion_matrix_svm_pca[i, :].sum() - confusion_matrix_svm_pca[i, i]  # Somma della riga, escludendo la diagonale\n",
        "    fp = confusion_matrix_svm_pca[:, i].sum() - confusion_matrix_svm_pca[i, i]  # Somma della colonna, escludendo la diagonale\n",
        "\n",
        "    print(f\"\\nClasse: {label}\")\n",
        "    print(f\"False Negative (FN): {fn}\")\n",
        "    print(f\"False Positive (FP): {fp}\")"
      ],
      "metadata": {
        "id": "1paQi4Ys3pGg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "# Assume che 'target' sia la colonna target del tuo dataset\n",
        "target = dataset_subset[' Label']\n",
        "X_train_svm_pca, X_test_svm_pca, y_train_svm_pca, y_test_svm_pca = train_test_split(pca_res[:, :30], target, test_size=0.2, random_state=42)\n",
        "\n",
        "# Support Vector Machine (SVM)\n",
        "svm_model_pca = SVC()\n",
        "svm_model_pca.fit(X_train_svm_pca, y_train_svm_pca)\n",
        "svm_predictions_pca = svm_model_pca.predict(X_test_svm_pca)\n",
        "\n",
        "# Valutazione del modello SVM\n",
        "svm_accuracy_pca = accuracy_score(y_test_svm_pca, svm_predictions_pca)\n",
        "print(\"Accuratezza SVM PCA:\", svm_accuracy_pca)\n",
        "\n",
        "# Matrice di confusione SVM\n",
        "svm_conf_matrix_pca = confusion_matrix(y_test_svm_pca, svm_predictions_pca)\n",
        "print(\"\\nMatrice di Confusione SVM PCA:\")\n",
        "print(svm_conf_matrix_pca)"
      ],
      "metadata": {
        "id": "0YDRq1jiTZWY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Supponendo che tu abbia gi i pesi per i tre metodi\n",
        "# Ad esempio, i pesi assegnati dalle tecniche di Borda e wBorda sono rispettivamente 'borda_weights_pca', 'borda_weights_boruta', 'borda_weights_rf'\n",
        "# e 'wborda_weights_pca', 'wborda_weights_boruta', 'wborda_weights_rf'\n",
        "\n",
        "total_accuracy = accuracy_pca + accuracy_boruta + accuracy_rf\n",
        "alpha_pca = accuracy_pca / total_accuracy\n",
        "alpha_boruta = accuracy_boruta / total_accuracy\n",
        "alpha_rf = accuracy_rf / total_accuracy\n",
        "\n",
        "# Calcola il ranking combinato\n",
        "combined_ranking = {}\n",
        "\n",
        "for feature in feature_df['Feature']:\n",
        "    borda_score_pca = weights_pca.get(feature, 0)  # Se la feature non 챔 presente, assegna 0\n",
        "    borda_score_boruta = weights_boruta.get(feature, 0)  # Se la feature non 챔 presente, assegna 0\n",
        "    borda_score_rf = weights_rf.get(feature, 0)  # Se la feature non 챔 presente, assegna 0\n",
        "\n",
        "    wborda_score_pca = weights_pca.get(feature, 0)  # Se la feature non 챔 presente, assegna 0\n",
        "    wborda_score_boruta = weights_boruta.get(feature, 0)  # Se la feature non 챔 presente, assegna 0\n",
        "    wborda_score_rf = weights_rf.get(feature, 0)  # Se la feature non 챔 presente, assegna 0\n",
        "\n",
        "    # Calcola il ranking combinato\n",
        "    combined_score = (\n",
        "        alpha_pca * borda_score_pca + alpha_boruta * borda_score_boruta + alpha_rf * borda_score_rf +\n",
        "        alpha_pca * wborda_score_pca + alpha_boruta * wborda_score_boruta + alpha_rf * wborda_score_rf\n",
        "    )\n",
        "\n",
        "    combined_ranking[feature] = combined_score\n",
        "\n",
        "# Ordina le feature in base al ranking combinato\n",
        "combined_ranking_sorted = {k: v for k, v in sorted(combined_ranking.items(), key=lambda item: item[1], reverse=True)}\n",
        "\n",
        "# Stampa il ranking combinato\n",
        "for feature, score in combined_ranking_sorted.items():\n",
        "    print(f\"Feature: {feature}, Punteggio Combinato: {score:.4f}\")\n"
      ],
      "metadata": {
        "id": "JJPjL0UZzwF8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Seleziona le prime 20 feature dal ranking combinato\n",
        "top_features_combined = list(combined_ranking_sorted.keys())[:20]\n",
        "\n",
        "# Aggiungi il label al set di feature selezionate\n",
        "selected_features_combined = [' Label'] + top_features_combined\n",
        "\n",
        "# Crea un nuovo dataset con solo le prime 20 feature e il label\n",
        "new_dataset_combined = dataset_subset[selected_features_combined]\n",
        "\n",
        "# Visualizza le prime righe del nuovo dataset\n",
        "print(new_dataset_combined.head())"
      ],
      "metadata": {
        "id": "UY4VPmT0uT0N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.experimental import enable_halving_search_cv\n",
        "from sklearn.model_selection import HalvingGridSearchCV\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "# Separazione delle feature e del label nel nuovo dataset\n",
        "X_rf_combined = new_dataset_combined.drop(' Label', axis=1)  # Rimuovi la colonna del label\n",
        "y_rf_combined = new_dataset_combined[' Label']\n",
        "\n",
        "# Creazione dei set di allenamento e test\n",
        "X_train_rf_combined, X_test_rf_combined, y_train_rf_combined, y_test_rf_combined = train_test_split(X_rf_combined, y_rf_combined, test_size=0.2, random_state=42)\n",
        "\n",
        "# Allenamento del modello RandomForest\n",
        "model_rf_combined = RandomForestClassifier()\n",
        "\n",
        "# Definizione della griglia dei parametri da cercare\n",
        "param_grid = {\"max_depth\": [3, None], \"min_samples_split\": [5, 10]}\n",
        "\n",
        "# Ricerca dei parametri migliori con Halving Grid Search CV\n",
        "search = HalvingGridSearchCV(model_rf_combined, param_grid, random_state=42).fit(X_train_rf_combined, y_train_rf_combined)\n",
        "best_combined_params = search.best_params_\n",
        "\n",
        "# Visualizzazione dei parametri migliori\n",
        "print(\"Migliori parametri per RandomForest:\", best_combined_params)\n",
        "\n",
        "# Utilizzo dei migliori parametri per allenare il modello\n",
        "best_model_combined = RandomForestClassifier(**best_combined_params)\n",
        "best_model_combined.fit(X_train_rf_combined, y_train_rf_combined)\n",
        "\n",
        "# Valutazione del modello RandomForest con i migliori parametri\n",
        "predictions_combined_best = best_model_combined.predict(X_test_rf_combined)\n",
        "accuracy_combined_best = accuracy_score(y_test_rf_combined, predictions_combined_best)\n",
        "confusion_matrix_combined_best = confusion_matrix(y_test_rf_combined, predictions_combined_best)\n",
        "\n",
        "# Visualizza i risultati con i migliori parametri\n",
        "print(\"Accuratezza RandomForest R.combinato con i migliori parametri:\", accuracy_combined_best)\n",
        "print(\"Matrice di confusione RandomForest R.combinato con i migliori parametri:\\n\", confusion_matrix_combined_best)"
      ],
      "metadata": {
        "id": "7acutl9zb4cC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.experimental import enable_halving_search_cv\n",
        "from sklearn.model_selection import HalvingGridSearchCV\n",
        "\n",
        "# Separazione delle feature e del label nel nuovo dataset\n",
        "X_svm_combined = new_dataset_combined.drop(' Label', axis=1)  # Rimuovi la colonna del label\n",
        "y_svm_combined = new_dataset_combined[' Label']\n",
        "\n",
        "# Creazione dei set di allenamento e test\n",
        "X_train_svm_combined, X_test_svm_combined, y_train_svm_combined, y_test_svm_combined = train_test_split(X_svm_combined, y_svm_combined, test_size=0.2, random_state=42)\n",
        "\n",
        "# Allenamento del modello SVM\n",
        "model_svm_combined = SVC()\n",
        "\n",
        "# Definisci la griglia degli iperparametri\n",
        "param_grid = {'C': [0.1, 0.5, 1, 2, 5, 10], 'kernel': ['linear', 'rbf', 'sigmoid', 'poly'], 'tol': [1e-3, 1e-2]}\n",
        "\n",
        "# Applica Halving Grid Search CV\n",
        "search_svm = HalvingGridSearchCV(model_svm_combined, param_grid, cv=5, factor=2, max_resources=110, min_resources=10, aggressive_elimination=False, random_state = 42)\n",
        "search_svm.fit(X_train_svm_combined, y_train_svm_combined)\n",
        "\n",
        "# Ottieni i migliori parametri\n",
        "best_svm_params = search_svm.best_params_\n",
        "\n",
        "# Visualizzazione dei parametri migliori\n",
        "print(\"Migliori parametri per SVM:\", best_svm_params)\n",
        "\n",
        "# Utilizzo dei migliori parametri per allenare il modello\n",
        "best_model_svm_combined = SVC(**best_svm_params)\n",
        "best_model_svm_combined.fit(X_train_svm_combined, y_train_svm_combined)\n",
        "\n",
        "# Valutazione del modello RandomForest con i migliori parametri\n",
        "predictions_svm_combined = best_model_svm_combined.predict(X_test_svm_combined)\n",
        "accuracy_svm_combined = accuracy_score(y_test_svm_combined, predictions_svm_combined)\n",
        "confusion_matrix_svm_combined = confusion_matrix(y_test_svm_combined, predictions_svm_combined)\n",
        "\n",
        "# Visualizza i risultati con i migliori parametri\n",
        "print(\"Accuratezza SVM R.combinato con i migliori parametri:\", accuracy_svm_combined)\n",
        "print(\"Matrice di confusione SVM R.combinato con i migliori parametri:\\n\", confusion_matrix_svm_combined)"
      ],
      "metadata": {
        "id": "syWOr0z-b4Dq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#RF per ranking combinato\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "# Separazione delle feature e del label nel nuovo dataset\n",
        "X_rf_combined = new_dataset_combined.drop(' Label', axis=1)  # Rimuovi la colonna del label\n",
        "y_rf_combined = new_dataset_combined[' Label']\n",
        "\n",
        "# Creazione dei set di allenamento e test\n",
        "X_train_rf_combined, X_test_rf_combined, y_train_rf_combined, y_test_rf_combined = train_test_split(X_rf_combined, y_rf_combined, test_size=0.2, random_state=42)\n",
        "\n",
        "# Allenamento del modello RandomForest\n",
        "model_rf_combined = RandomForestClassifier()\n",
        "model_rf_combined.fit(X_train_rf_combined, y_train_rf_combined)\n",
        "\n",
        "# Valutazione del modello RandomForest\n",
        "predictions_rf_combined = model_rf_combined.predict(X_test_rf_combined)\n",
        "accuracy_rf_combined = accuracy_score(y_test_rf_combined, predictions_rf_combined)\n",
        "confusion_matrix_rf_combined = confusion_matrix(y_test_rf_combined, predictions_rf_combined)\n",
        "\n",
        "# Visualizza i risultati per RandomForest\n",
        "print(\"Accuratezza RandomForest Ranking Combinato:\", accuracy_rf_combined)\n",
        "print(\"Matrice Confusione RandomForest Ranking Combinato:\\n\", confusion_matrix_rf_combined)\n"
      ],
      "metadata": {
        "id": "zhwFeZBEui90"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#RF per ranking combinato\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "# Separazione delle feature e del label nel nuovo dataset\n",
        "X_rf_combined = new_dataset_combined.drop(' Label', axis=1)  # Rimuovi la colonna del label\n",
        "y_rf_combined = new_dataset_combined[' Label']\n",
        "\n",
        "# Creazione dei set di allenamento e test\n",
        "X_train_rf_combined, X_test_rf_combined, y_train_rf_combined, y_test_rf_combined = train_test_split(X_rf_combined, y_rf_combined, test_size=0.2, random_state=42)\n",
        "\n",
        "# Allenamento del modello RandomForest\n",
        "model_rf_combined = RandomForestClassifier()\n",
        "model_rf_combined.fit(X_train_rf_combined, y_train_rf_combined)\n",
        "\n",
        "# Valutazione del modello RandomForest\n",
        "predictions_rf_combined = model_rf_combined.predict(X_test_rf_combined)\n",
        "accuracy_rf_combined = accuracy_score(y_test_rf_combined, predictions_rf_combined)\n",
        "confusion_matrix_rf_combined = confusion_matrix(y_test_rf_combined, predictions_rf_combined)\n",
        "\n",
        "# Visualizza i risultati per RandomForest\n",
        "print(\"Accuratezza RandomForest Ranking Combinato:\", accuracy_rf_combined)\n",
        "print(\"Matrice Confusione RandomForest Ranking Combinato:\\n\", confusion_matrix_rf_combined)\n",
        "\n",
        "class_report_combined = classification_report(y_test_rf_combined, predictions_rf_combined)\n",
        "print(\"Classification Report - Random Forest RFC:\\n\", class_report_combined)\n",
        "\n",
        "# Estrai le etichette delle classi dal modello\n",
        "class_labels_combined = model_rf_combined.classes_\n",
        "\n",
        "# Per ogni classe, estrai FN e FP dalla matrice di confusione\n",
        "for i, label in enumerate(class_labels_combined):\n",
        "    fn = confusion_matrix_rf_combined[i, :].sum() - confusion_matrix_rf_combined[i, i]  # Somma della riga, escludendo la diagonale\n",
        "    fp = confusion_matrix_rf_combined[:, i].sum() - confusion_matrix_rf_combined[i, i]  # Somma della colonna, escludendo la diagonale\n",
        "\n",
        "    print(f\"\\nClasse: {label}\")\n",
        "    print(f\"False Negative (FN): {fn}\")\n",
        "    print(f\"False Positive (FP): {fp}\")"
      ],
      "metadata": {
        "id": "APBS3EAr4rz0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#SVM per ranking combinato\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "# Separazione delle feature e del label nel nuovo dataset\n",
        "X_svm_combined = new_dataset_combined.drop(' Label', axis=1)  # Rimuovi la colonna del label\n",
        "y_svm_combined = new_dataset_combined[' Label']\n",
        "\n",
        "# Creazione dei set di allenamento e test\n",
        "X_train_svm_combined, X_test_svm_combined, y_train_svm_combined, y_test_svm_combined = train_test_split(X_svm_combined, y_svm_combined, test_size=0.2, random_state=42)\n",
        "\n",
        "# Allenamento del modello SVM\n",
        "model_svm_combined = SVC()\n",
        "model_svm_combined.fit(X_train_svm_combined, y_train_svm_combined)\n",
        "\n",
        "# Valutazione del modello SVM\n",
        "predictions_svm_combined = model_svm_combined.predict(X_test_svm_combined)\n",
        "accuracy_svm_combined = accuracy_score(y_test_svm_combined, predictions_svm_combined)\n",
        "confusion_matrix_svm_combined = confusion_matrix(y_test_svm_combined, predictions_svm_combined)\n",
        "\n",
        "# Visualizza i risultati per SVM\n",
        "print(\"Accuracy SVM (con le prime 20 feature):\", accuracy_svm_combined)\n",
        "print(\"Confusion Matrix SVM (con le prime 20 feature):\\n\", confusion_matrix_svm_combined)\n",
        "\n",
        "class_report_svm_combined = classification_report(y_test_svm_combined, predictions_svm_combined)\n",
        "print(\"Classification Report - Random Forest RFC:\\n\", class_report_svm_combined)\n",
        "\n",
        "# Estrai le etichette delle classi dal modello\n",
        "class_labels_svm_combined = model_svm_combined.classes_\n",
        "\n",
        "# Per ogni classe, estrai FN e FP dalla matrice di confusione\n",
        "for i, label in enumerate(class_labels_svm_combined):\n",
        "    fn = confusion_matrix_svm_combined[i, :].sum() - confusion_matrix_svm_combined[i, i]  # Somma della riga, escludendo la diagonale\n",
        "    fp = confusion_matrix_svm_combined[:, i].sum() - confusion_matrix_svm_combined[i, i]  # Somma della colonna, escludendo la diagonale\n",
        "\n",
        "    print(f\"\\nClasse: {label}\")\n",
        "    print(f\"False Negative (FN): {fn}\")\n",
        "    print(f\"False Positive (FP): {fp}\")"
      ],
      "metadata": {
        "id": "oXJieBSj5Q6r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#SVM per ranking combinato\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "# Separazione delle feature e del label nel nuovo dataset\n",
        "X_svm_combined = new_dataset_combined.drop(' Label', axis=1)  # Rimuovi la colonna del label\n",
        "y_svm_combined = new_dataset_combined[' Label']\n",
        "\n",
        "# Creazione dei set di allenamento e test\n",
        "X_train_svm_combined, X_test_svm_combined, y_train_svm_combined, y_test_svm_combined = train_test_split(X_svm_combined, y_svm_combined, test_size=0.2, random_state=42)\n",
        "\n",
        "# Allenamento del modello SVM\n",
        "model_svm_combined = SVC()\n",
        "model_svm_combined.fit(X_train_svm_combined, y_train_svm_combined)\n",
        "\n",
        "# Valutazione del modello SVM\n",
        "predictions_svm_combined = model_svm_combined.predict(X_test_svm_combined)\n",
        "accuracy_svm_combined = accuracy_score(y_test_svm_combined, predictions_svm_combined)\n",
        "confusion_matrix_svm_combined = confusion_matrix(y_test_svm_combined, predictions_svm_combined)\n",
        "\n",
        "# Visualizza i risultati per SVM\n",
        "print(\"Accuracy SVM (con le prime 20 feature):\", accuracy_svm_combined)\n",
        "print(\"Confusion Matrix SVM (con le prime 20 feature):\\n\", confusion_matrix_svm_combined)\n"
      ],
      "metadata": {
        "id": "E4dtxtpEvL79"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HAlqJXWQGQ8A"
      },
      "outputs": [],
      "source": [
        "tsne = TSNE(n_components=2, verbose=0, perplexity=100, n_iter=1000)\n",
        "tsne_res = tsne.fit_transform(pca_res)\n",
        "print(\"done\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Go0j1ixTHFSY"
      },
      "outputs": [],
      "source": [
        "dataset_subset['tsne_firstD'] = tsne_res[:,0]\n",
        "dataset_subset['tsne_secondD'] = tsne_res[:,1]\n",
        "dataset_subset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6-_EKfj6gNRH"
      },
      "outputs": [],
      "source": [
        "custom_palette = [\n",
        "    (0, 0, 0),       # Nero\n",
        "    (1, 1, 0),       # Giallo\n",
        "    (1, 0, 0),       # Rosso\n",
        "    (0, 1, 0),       # Verde\n",
        "    (1, 0.549, 0),   # Arancione\n",
        "    (1, 0, 1),       # Fuchsia\n",
        "    (0, 1, 1),       # Ciano\n",
        "    (0, 0, 1),       # Blu\n",
        "    (0.502, 0, 0.502),  # Lilla\n",
        "    (0.502, 0.502, 0),  # Olive\n",
        "    (0, 0.749, 1)   # Turchese\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mfq8RCFcHFKf"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(16,16))\n",
        "\n",
        "sns.scatterplot(\n",
        "    x=\"tsne_firstD\",\n",
        "    y=\"tsne_secondD\",\n",
        "    palette=custom_palette,\n",
        "    data=dataset_subset,\n",
        "    hue=' Label',\n",
        "    legend=\"full\",\n",
        "    alpha=0.75\n",
        ")\n",
        "\n",
        "plt.xlabel('tsne_firstD')\n",
        "plt.ylabel('tsne_secondD')\n",
        "plt.title('Anomaly Detection')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1cDtynI638ennqI7o74wj0VNoOdR2rpsZ",
      "authorship_tag": "ABX9TyNPwPjbKZjZFJCntkxByJJr",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}