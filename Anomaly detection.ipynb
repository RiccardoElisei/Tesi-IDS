{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RiccardoElisei/Tesi-IDS/blob/main/Anomaly%20detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wmc4uLBtuOV5"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import glob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yswd3EYWuTzi"
      },
      "outputs": [],
      "source": [
        "path = \"drive/MyDrive/MachineLearningCVE/\"\n",
        "files = [file for file in glob.glob(path + \"**/*.csv\", recursive=True)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1EWZcoiZuV5y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fd3ba9c-2555-4b32-decc-157e8e23b431"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "drive/MyDrive/MachineLearningCVE/Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv\n",
            "drive/MyDrive/MachineLearningCVE/Friday-WorkingHours-Afternoon-PortScan.pcap_ISCX.csv\n",
            "drive/MyDrive/MachineLearningCVE/Friday-WorkingHours-Morning.pcap_ISCX.csv\n",
            "drive/MyDrive/MachineLearningCVE/Monday-WorkingHours.pcap_ISCX.csv\n",
            "drive/MyDrive/MachineLearningCVE/Thursday-WorkingHours-Afternoon-Infilteration.pcap_ISCX.csv\n",
            "drive/MyDrive/MachineLearningCVE/Thursday-WorkingHours-Morning-WebAttacks.pcap_ISCX.csv\n",
            "drive/MyDrive/MachineLearningCVE/Tuesday-WorkingHours.pcap_ISCX.csv\n",
            "drive/MyDrive/MachineLearningCVE/Wednesday-workingHours.pcap_ISCX.csv\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[None, None, None, None, None, None, None, None]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "[print(f) for f in files]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KKeMzcfpuX_T"
      },
      "outputs": [],
      "source": [
        "dataset = [pd.read_csv(f) for f in files]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g-bT7D_LuaMs"
      },
      "outputs": [],
      "source": [
        "for d in dataset:\n",
        "    print(d.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q_lcmgqSujjE"
      },
      "outputs": [],
      "source": [
        "dataset = pd.concat([d for d in dataset]).drop_duplicates(keep=False)\n",
        "dataset.reset_index(drop=True, inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NHEgvkQsujcF"
      },
      "outputs": [],
      "source": [
        "dataset.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y8HKfJbxujZQ"
      },
      "outputs": [],
      "source": [
        "dataset.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-yhx9bfAujWm"
      },
      "outputs": [],
      "source": [
        "dataset.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ILtDcIhGujTv"
      },
      "outputs": [],
      "source": [
        "dataset.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KQZZ61upujQ3"
      },
      "outputs": [],
      "source": [
        "print(dataset[' Label'].unique())\n",
        "len(dataset[' Label'].unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L5M8U7tWujOA"
      },
      "outputs": [],
      "source": [
        "label_names = dataset[' Label'].unique()\n",
        "\n",
        "import re\n",
        "\n",
        "label_names = [re.sub(\"[^a-zA-Z ]+\", \"\", l) for l in label_names]\n",
        "label_names = [re.sub(\"[\\s\\s]\", '_', l) for l in label_names]\n",
        "label_names = [lab.replace(\"__\", \"_\") for lab in label_names]\n",
        "\n",
        "label_names, len(label_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JY7EyKpjujLJ"
      },
      "outputs": [],
      "source": [
        "labels = dataset[' Label'].unique()\n",
        "\n",
        "for i in range(0,len(label_names)):\n",
        "    dataset[' Label'] = dataset[' Label'].replace({labels[i] : label_names[i]})\n",
        "\n",
        "dataset[' Label'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cW0bnB8KujIS"
      },
      "outputs": [],
      "source": [
        "dataset.isnull().values.any()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oGlJ2nxSujFZ"
      },
      "outputs": [],
      "source": [
        "[col for col in dataset if dataset[col].isnull().values.any()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bIarotRxujCx"
      },
      "outputs": [],
      "source": [
        "dataset['Flow Bytes/s'].isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2dONqw8kui_6"
      },
      "outputs": [],
      "source": [
        "before = dataset.shape\n",
        "dataset.dropna(inplace=True)\n",
        "after = dataset.shape\n",
        "before[0] - after[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0DkLQ2tMui9T"
      },
      "outputs": [],
      "source": [
        "dataset.isnull().any().any()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-h1cxUBGui6K"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kHwKdIOCui3j"
      },
      "outputs": [],
      "source": [
        "labl = dataset[' Label']\n",
        "dataset = dataset.loc[:, dataset.columns != ' Label'].astype('float64')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t0Mx9tcrui08"
      },
      "outputs": [],
      "source": [
        "np.all(np.isfinite(dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0IwOYWXuuix1"
      },
      "outputs": [],
      "source": [
        "nonfinite = [col for col in dataset if not np.all(np.isfinite(dataset[col]))]\n",
        "nonfinite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KrDswaVBuiu8"
      },
      "outputs": [],
      "source": [
        "finite = np.isfinite(dataset['Flow Bytes/s']).sum()\n",
        "\n",
        "dataset.shape[0] - finite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ym3G33yvuimk"
      },
      "outputs": [],
      "source": [
        "finite = np.isfinite(dataset[' Flow Packets/s']).sum()\n",
        "\n",
        "dataset.shape[0] - finite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vxs6IUa-uiX3"
      },
      "outputs": [],
      "source": [
        "dataset = dataset.replace([np.inf, -np.inf], np.nan)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZPj4yOpQvKsq"
      },
      "outputs": [],
      "source": [
        "dataset = dataset.merge(labl, how='outer', left_index=True, right_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XmFufGUMvKp-"
      },
      "outputs": [],
      "source": [
        "dataset.dropna(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SK7DDfhXvKnl"
      },
      "outputs": [],
      "source": [
        "dataset.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hi7GSp2cBDFt"
      },
      "outputs": [],
      "source": [
        "dataset.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2cW7iE0EQmao"
      },
      "outputs": [],
      "source": [
        "conteggio_per_label = dataset[' Label'].value_counts()\n",
        "\n",
        "for label, conteggio in conteggio_per_label.items():\n",
        "    print(f\"Numero di flussi per il label '{label}': {conteggio}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6KfaGBkaE2Ea"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pGgZJ7_5E166"
      },
      "outputs": [],
      "source": [
        "np.random.seed(42)\n",
        "rand_perm = np.random.permutation(dataset.shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d5dmOcWBFtY1"
      },
      "outputs": [],
      "source": [
        "feature_cols = dataset.columns[:-1]\n",
        "\n",
        "dataset_subset = dataset.iloc[rand_perm[:9975], :]\n",
        "\n",
        "web_attack_xss_rows = dataset[dataset[' Label'] == 'Web_Attack_XSS'].sample(n=8)\n",
        "dataset_subset = pd.concat([dataset_subset, web_attack_xss_rows], ignore_index=True)\n",
        "\n",
        "infiltration_rows = dataset[dataset[' Label'] == 'Infiltration'].sample(n=7)\n",
        "dataset_subset = pd.concat([dataset_subset, infiltration_rows], ignore_index=True)\n",
        "\n",
        "web_attack_sql_injection_rows = dataset[dataset[' Label'] == 'Web_Attack_Sql_Injection'].sample(n=6)\n",
        "dataset_subset = pd.concat([dataset_subset, web_attack_sql_injection_rows], ignore_index=True)\n",
        "\n",
        "heartbleed_rows = dataset[dataset[' Label'] == 'Heartbleed'].sample(n=4)\n",
        "dataset_subset = pd.concat([dataset_subset, heartbleed_rows], ignore_index=True)\n",
        "\n",
        "dataset_subset.to_csv('dataset_subset.csv', index=False)\n",
        "\n",
        "conteggio_per_label = dataset_subset[' Label'].value_counts()\n",
        "\n",
        "for label, conteggio in conteggio_per_label.items():\n",
        "   print(f\"Numero di flussi per il label '{label}': {conteggio}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q8fA1ISLlkWP"
      },
      "outputs": [],
      "source": [
        "feature_cols = dataset.columns[:-1]\n",
        "dataset_subset = dataset.iloc[rand_perm[:10000],:]\n",
        "dataset_subset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c8ph0_WcnmTy"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "X = dataset_subset[feature_cols]\n",
        "Y = dataset_subset[' Label']\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=None, random_state=42)\n",
        "\n",
        "clf = RandomForestClassifier()\n",
        "\n",
        "clf.fit(X_train, Y_train)\n",
        "\n",
        "Y_pred = clf.predict(X_test)\n",
        "accuracy_rf = accuracy_score(Y_test, Y_pred)\n",
        "\n",
        "feature_importance = clf.feature_importances_\n",
        "\n",
        "feature_df = pd.DataFrame({'Feature': X.columns, 'Importance': feature_importance})\n",
        "\n",
        "feature_df = feature_df.sort_values(by='Importance', ascending=False)\n",
        "\n",
        "weights_rf = {feature: weight for weight, feature in enumerate(feature_df['Feature'], start=1)}\n",
        "\n",
        "plt.figure(figsize=(15, 8))\n",
        "plt.bar(feature_df['Feature'][:50], feature_df['Importance'][:50], color='skyblue')\n",
        "plt.xlabel('Feature')\n",
        "plt.ylabel('Importance')\n",
        "plt.title('Feature RandomForsetClassifier')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(feature_df.head(50))\n",
        "\n",
        "print(accuracy_rf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hjdnVrD-8Vzm"
      },
      "outputs": [],
      "source": [
        "# Seleziona le prime 10/20/30 feature dal classificatore RandomForest\n",
        "top_features_rf = feature_df['Feature'][:30].tolist()\n",
        "\n",
        "selected_features_rf = [' Label'] + top_features_rf\n",
        "\n",
        "new_dataset_rf = dataset_subset[selected_features_rf]\n",
        "\n",
        "print(new_dataset_rf.head())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.experimental import enable_halving_search_cv\n",
        "from sklearn.model_selection import HalvingGridSearchCV\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "from sklearn.metrics import log_loss, roc_auc_score\n",
        "\n",
        "X_rf = new_dataset_rf.drop(' Label', axis=1)\n",
        "y_rf = new_dataset_rf[' Label']\n",
        "\n",
        "X_train_rf, X_test_rf, y_train_rf, y_test_rf = train_test_split(X_rf, y_rf, test_size=None, random_state=42)\n",
        "\n",
        "model_rf = RandomForestClassifier()\n",
        "\n",
        "param_grid = {\"max_depth\": [3, None], \"min_samples_split\": [5, 10]}\n",
        "\n",
        "# Ricerca dei parametri migliori con Halving Grid Search CV\n",
        "search = HalvingGridSearchCV(model_rf, param_grid, random_state=42).fit(X_rf, y_rf)\n",
        "best_rf_params = search.best_params_\n",
        "\n",
        "print(\"Migliori parametri per RandomForest:\", best_rf_params)\n",
        "\n",
        "best_model_rf = RandomForestClassifier(**best_rf_params)\n",
        "best_model_rf.fit(X_rf, y_rf)\n",
        "\n",
        "predictions_rf_best = best_model_rf.predict(X_rf)\n",
        "accuracy_rf_best = accuracy_score(y_rf, predictions_rf_best)\n",
        "confusion_matrix_rf_best = confusion_matrix(y_rf, predictions_rf_best)\n",
        "\n",
        "precision_rf_best = precision_score(y_rf, predictions_rf_best, average='weighted')\n",
        "recall_rf_best = recall_score(y_rf, predictions_rf_best, average='weighted')\n",
        "f1_rf_best = f1_score(y_rf, predictions_rf_best, average='weighted')\n",
        "\n",
        "predictions_proba_rf_best = best_model_rf.predict_proba(X_rf)\n",
        "\n",
        "logloss_rf_best = log_loss(y_rf, predictions_proba_rf_best)\n",
        "\n",
        "roc_auc_rf_best = roc_auc_score(y_rf, predictions_proba_rf_best, multi_class='ovr')\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(confusion_matrix_rf_best, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "print(\"Accuratezza RandomForest RFC con i migliori parametri:\", accuracy_rf_best)\n",
        "print(\"Precisione RandomForest RFC con i migliori parametri:\", precision_rf_best)\n",
        "print(\"Recall RandomForest RFC con i migliori parametri:\", recall_rf_best)\n",
        "print(\"F1-score RandomForest RFC con i migliori parametri:\", f1_rf_best)\n",
        "print(\"Log-loss RandomForest RFC con i migliori parametri:\", logloss_rf_best)\n",
        "print(\"ROC-AUC RandomForest RFC con i migliori parametri:\", roc_auc_rf_best)\n",
        "\n",
        "print(\"Label nel training set:\")\n",
        "print(y_train_rf.value_counts())\n",
        "\n",
        "print(\"\\nLabel nel test set:\")\n",
        "print(y_test_rf.value_counts())\n"
      ],
      "metadata": {
        "id": "HNQwDkb8jGG5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FD04hYZdx5Vy"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.experimental import enable_halving_search_cv\n",
        "from sklearn.model_selection import HalvingGridSearchCV\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "from sklearn.metrics import log_loss, roc_auc_score\n",
        "\n",
        "X_rf = new_dataset_rf.drop(' Label', axis=1)\n",
        "y_rf = new_dataset_rf[' Label']\n",
        "\n",
        "X_train_rf, X_test_rf, y_train_rf, y_test_rf = train_test_split(X_rf, y_rf, test_size=0.2, random_state=42)\n",
        "\n",
        "model_rf = RandomForestClassifier()\n",
        "\n",
        "# Definizione della griglia dei parametri da cercare\n",
        "param_grid = {\"max_depth\": [3, None], \"min_samples_split\": [5, 10]}\n",
        "\n",
        "# Ricerca dei parametri migliori con Halving Grid Search CV\n",
        "search = HalvingGridSearchCV(model_rf, param_grid, random_state=42).fit(X_train_rf, y_train_rf)\n",
        "best_rf_params = search.best_params_\n",
        "\n",
        "print(\"Migliori parametri per RandomForest:\", best_rf_params)\n",
        "\n",
        "best_model_rf = RandomForestClassifier(**best_rf_params)\n",
        "best_model_rf.fit(X_train_rf, y_train_rf)\n",
        "\n",
        "predictions_rf_best = best_model_rf.predict(X_test_rf)\n",
        "accuracy_rf_best = accuracy_score(y_test_rf, predictions_rf_best)\n",
        "confusion_matrix_rf_best = confusion_matrix(y_test_rf, predictions_rf_best)\n",
        "\n",
        "precision_rf_best = precision_score(y_test_rf, predictions_rf_best, average='weighted')\n",
        "recall_rf_best = recall_score(y_test_rf, predictions_rf_best, average='weighted')\n",
        "f1_rf_best = f1_score(y_test_rf, predictions_rf_best, average='weighted')\n",
        "\n",
        "predictions_proba_rf_best = best_model_rf.predict_proba(X_test_rf)\n",
        "\n",
        "logloss_rf_best = log_loss(y_test_rf, predictions_proba_rf_best)\n",
        "\n",
        "roc_auc_rf_best = roc_auc_score(y_test_rf, predictions_proba_rf_best, multi_class='ovr')\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(confusion_matrix_rf_best, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "print(\"Accuratezza RandomForest RFC con i migliori parametri:\", accuracy_rf_best)\n",
        "print(\"Precisione RandomForest RFC con i migliori parametri:\", precision_rf_best)\n",
        "print(\"Recall RandomForest RFC con i migliori parametri:\", recall_rf_best)\n",
        "print(\"F1-score RandomForest RFC con i migliori parametri:\", f1_rf_best)\n",
        "print(\"Log-loss RandomForest RFC con i migliori parametri:\", logloss_rf_best)\n",
        "print(\"ROC-AUC RandomForest RFC con i migliori parametri:\", roc_auc_rf_best)\n",
        "\n",
        "print(\"Label nel training set:\")\n",
        "print(y_train_rf.value_counts())\n",
        "\n",
        "print(\"\\nLabel nel test set:\")\n",
        "print(y_test_rf.value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.experimental import enable_halving_search_cv\n",
        "from sklearn.model_selection import HalvingGridSearchCV\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
        "from sklearn.metrics import log_loss, roc_auc_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "X_svm = new_dataset_rf.drop(' Label', axis=1)\n",
        "y_svm = new_dataset_rf[' Label']\n",
        "\n",
        "X_train_svm, X_test_svm, y_train_svm, y_test_svm = train_test_split(X_svm, y_svm, test_size=None, random_state=42)\n",
        "\n",
        "model_svm = SVC(probability=True)\n",
        "\n",
        "# Definizione della griglia dei parametri da cercare\n",
        "param_grid = {'C': [0.1, 0.5, 1, 2, 5, 10], 'kernel': ['linear', 'rbf', 'sigmoid', 'poly'], 'tol': [1e-3, 1e-2]}\n",
        "\n",
        "# Ricerca dei parametri migliori con Halving Grid Search CV\n",
        "search_svm = HalvingGridSearchCV(model_svm, param_grid, cv=5, random_state=42).fit(X_svm, y_svm)\n",
        "best_svm_params = search_svm.best_params_\n",
        "\n",
        "print(\"Migliori parametri per Support Vector Machine:\", best_svm_params)\n",
        "\n",
        "best_model_svm = SVC(**best_svm_params, probability=True)\n",
        "best_model_svm.fit(X_svm, y_svm)\n",
        "\n",
        "predictions_svm_best = best_model_svm.predict(X_svm)\n",
        "accuracy_svm_best = accuracy_score(y_svm, predictions_svm_best)\n",
        "confusion_matrix_svm_best = confusion_matrix(y_svm, predictions_svm_best)\n",
        "precision_svm_best = precision_score(y_svm, predictions_svm_best, average='weighted')\n",
        "recall_svm_best = recall_score(y_svm, predictions_svm_best, average='weighted')\n",
        "f1_svm_best = f1_score(y_svm, predictions_svm_best, average='weighted')\n",
        "\n",
        "predictions_proba_svm_best = best_model_svm.predict_proba(X_svm)\n",
        "\n",
        "logloss_svm_best = log_loss(y_svm, predictions_proba_svm_best)\n",
        "\n",
        "roc_auc_svm_best = roc_auc_score(y_svm, predictions_proba_svm_best, multi_class='ovr')\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(confusion_matrix_svm_best, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "print(\"Accuratezza Support Vector Machine con i migliori parametri:\", accuracy_svm_best)\n",
        "print(\"Precisione Support Vector Machine con i migliori parametri:\", precision_svm_best)\n",
        "print(\"Recall Support Vector Machine con i migliori parametri:\", recall_svm_best)\n",
        "print(\"F1-score Support Vector Machine con i migliori parametri:\", f1_svm_best)\n",
        "print(\"Log-loss Support Vector Machine con i migliori parametri:\", logloss_svm_best)\n",
        "print(\"ROC-AUC Support Vector Machine con i migliori parametri:\", roc_auc_svm_best)\n",
        "\n",
        "print(\"Label nel test set:\")\n",
        "print(y_test_svm.value_counts())\n"
      ],
      "metadata": {
        "id": "rK6Ck5nHHYlH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sT50MjHlQKlR"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.experimental import enable_halving_search_cv\n",
        "from sklearn.model_selection import HalvingGridSearchCV\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "from sklearn.metrics import log_loss, roc_auc_score\n",
        "\n",
        "X_svm_rf = new_dataset_rf.drop(' Label', axis=1)\n",
        "y_svm_rf = new_dataset_rf[' Label']\n",
        "\n",
        "X_train_svm_rf, X_test_svm_rf, y_train_svm_rf, y_test_svm_rf = train_test_split(X_svm_rf, y_svm_rf, test_size=None, random_state=42)\n",
        "\n",
        "model_svm = SVC()\n",
        "\n",
        "param_grid = {'C': [0.1, 0.5, 1, 2, 5, 10], 'kernel': ['linear', 'rbf', 'sigmoid', 'poly'], 'tol': [1e-3, 1e-2]}\n",
        "\n",
        "# Applica Halving Grid Search CV\n",
        "search_svm = HalvingGridSearchCV(model_svm, param_grid, cv=4, factor=2, max_resources=110, min_resources=10, aggressive_elimination=False, random_state=42)\n",
        "search_svm.fit(X_svm_rf, y_svm_rf)\n",
        "\n",
        "best_svm_params = search_svm.best_params_\n",
        "\n",
        "print(\"Migliori parametri per SVM:\", best_svm_params)\n",
        "\n",
        "best_model_svm_rf = SVC(**best_svm_params)\n",
        "best_model_svm_rf.fit(X_svm_rf, y_svm_rf)\n",
        "\n",
        "predictions_svm_rf = best_model_svm_rf.predict(X_svm_rf)\n",
        "accuracy_svm_rf = accuracy_score(y_svm_rf, predictions_svm_rf)\n",
        "confusion_matrix_svm_rf = confusion_matrix(y_svm_rf, predictions_svm_rf)\n",
        "precision_svm_rf = precision_score(y_svm_rf, predictions_svm_rf, average='weighted')\n",
        "recall_svm_rf = recall_score(y_svm_rf, predictions_svm_rf, average='weighted')\n",
        "f1_svm_rf = f1_score(y_svm_rf, predictions_svm_rf, average='weighted')\n",
        "\n",
        "predictions_proba_svm_rf = svm_calibrated.predict_proba(X_svm_rf)\n",
        "\n",
        "logloss_svm_rf = log_loss(y_svm_rf, predictions_proba_svm_rf)\n",
        "\n",
        "roc_auc_svm_rf = roc_auc_score(y_svm_rf, predictions_proba_svm_rf, multi_class='ovr')\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(confusion_matrix_svm_rf, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "print(\"Accuratezza SVM RFC con i migliori parametri:\", accuracy_svm_rf)\n",
        "print(\"Precisione SVM RFC con i migliori parametri:\", precision_svm_rf)\n",
        "print(\"Recall SVM RFC con i migliori parametri:\", recall_svm_rf)\n",
        "print(\"F1-score SVM RFC con i migliori parametri:\", f1_svm_rf)\n",
        "print(\"Log-loss SVM RFC con i migliori parametri:\", logloss_svm_rf)\n",
        "print(\"ROC-AUC SVM RFC con i migliori parametri:\", roc_auc_svm_rf)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score, log_loss, roc_auc_score\n",
        "\n",
        "X_rf = new_dataset_rf.drop(' Label', axis=1)\n",
        "y_rf = new_dataset_rf[' Label']\n",
        "\n",
        "model_rf = RandomForestClassifier()\n",
        "model_rf.fit(X_rf, y_rf)\n",
        "\n",
        "predictions_rf = model_rf.predict(X_rf)\n",
        "accuracy_rf = accuracy_score(y_rf, predictions_rf)\n",
        "confusion_matrix_rf = confusion_matrix(y_rf, predictions_rf)\n",
        "precision_rf = precision_score(y_rf, predictions_rf, average='weighted')\n",
        "recall_rf = recall_score(y_rf, predictions_rf, average='weighted')\n",
        "f1_rf = f1_score(y_rf, predictions_rf, average='weighted')\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(confusion_matrix_rf, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "print(\"Accuratezza RandomForest RFC:\", accuracy_rf)\n",
        "print(\"Precisione RandomForest RFC:\", precision_rf)\n",
        "print(\"Recall RandomForest RFC:\", recall_rf)\n",
        "print(\"F1-score RandomForest RFC:\", f1_rf)\n",
        "\n",
        "predictions_proba_rf = model_rf.predict_proba(X_rf)\n",
        "\n",
        "logloss_rf = log_loss(y_rf, predictions_proba_rf)\n",
        "\n",
        "roc_auc_rf = roc_auc_score(y_rf, predictions_proba_rf, average='weighted', multi_class='ovr')\n",
        "\n",
        "print(\"Log-loss RandomForest RFC:\", logloss_rf)\n",
        "print(\"ROC-AUC RandomForest RFC:\", roc_auc_rf)\n"
      ],
      "metadata": {
        "id": "VTgRcnM3YmMd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cga0PBcc91-_"
      },
      "outputs": [],
      "source": [
        "#Random Forest Test RFC\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
        "\n",
        "X_rf = new_dataset_rf.drop(' Label', axis=1)\n",
        "y_rf = new_dataset_rf[' Label']\n",
        "\n",
        "X_train_rf, X_test_rf, y_train_rf, y_test_rf = train_test_split(X_rf, y_rf, test_size=0.2, random_state=42)\n",
        "\n",
        "model_rf = RandomForestClassifier()\n",
        "model_rf.fit(X_train_rf, y_train_rf)\n",
        "\n",
        "predictions_rf = model_rf.predict(X_test_rf)\n",
        "accuracy_rf = accuracy_score(y_test_rf, predictions_rf)\n",
        "confusion_matrix_rf = confusion_matrix(y_test_rf, predictions_rf)\n",
        "precision_rf = precision_score(y_test_rf, predictions_rf, average='weighted')\n",
        "recall_rf = recall_score(y_test_rf, predictions_rf, average='weighted')\n",
        "f1_rf = f1_score(y_test_rf, predictions_rf, average='weighted')\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(confusion_matrix_rf, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "print(\"Accuratezza RandomForest RFC:\", accuracy_rf)\n",
        "print(\"Precisione RandomForest RFC:\", precision_rf)\n",
        "print(\"Recall RandomForest RFC:\", recall_rf)\n",
        "print(\"F1-score RandomForest RFC:\", f1_rf)\n",
        "\n",
        "from sklearn.metrics import log_loss, roc_auc_score\n",
        "\n",
        "predictions_proba_rf = model_rf.predict_proba(X_test_rf)\n",
        "\n",
        "logloss_rf = log_loss(y_test_rf, predictions_proba_rf)\n",
        "\n",
        "roc_auc_rf = roc_auc_score(y_test_rf, predictions_proba_rf, average='weighted', multi_class='ovr')\n",
        "\n",
        "print(\"Log-loss RandomForest RFC:\", logloss_rf)\n",
        "print(\"ROC-AUC RandomForest RFC:\", roc_auc_rf)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bArD4cS5yTLi"
      },
      "outputs": [],
      "source": [
        "#Random Forest Test RFC attacchi\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "X_rf = new_dataset_rf.drop(' Label', axis=1)\n",
        "y_rf = new_dataset_rf[' Label']\n",
        "\n",
        "X_train_rf, X_test_rf, y_train_rf, y_test_rf = train_test_split(X_rf, y_rf, test_size=0.2, random_state=42)\n",
        "\n",
        "model_rf = RandomForestClassifier()\n",
        "model_rf.fit(X_train_rf, y_train_rf)\n",
        "\n",
        "predictions_rf = model_rf.predict(X_test_rf)\n",
        "accuracy_rf = accuracy_score(y_test_rf, predictions_rf)\n",
        "confusion_matrix_rf = confusion_matrix(y_test_rf, predictions_rf)\n",
        "\n",
        "print(\"Accuratezza RandomForest RFC:\", accuracy_rf)\n",
        "print(\"Matrice di confusione RandomForest RFC:\\n\", confusion_matrix_rf)\n",
        "\n",
        "class_report_rf = classification_report(y_test_rf, predictions_rf)\n",
        "print(\"Classification Report - Random Forest RFC:\\n\", class_report_rf)\n",
        "\n",
        "class_labels_rf = model_rf.classes_\n",
        "\n",
        "for i, label in enumerate(class_labels_rf):\n",
        "    fn = confusion_matrix_rf[i, :].sum() - confusion_matrix_rf[i, i]\n",
        "    fp = confusion_matrix_rf[:, i].sum() - confusion_matrix_rf[i, i]\n",
        "\n",
        "    print(f\"\\nClasse: {label}\")\n",
        "    print(f\"False Negative (FN): {fn}\")\n",
        "    print(f\"False Positive (FP): {fp}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yV4JRCZNzIU9"
      },
      "outputs": [],
      "source": [
        "#SVM test RFC attacchi\n",
        "\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "X_svm_rf = new_dataset_rf.drop(' Label', axis=1)\n",
        "y_svm_rf = new_dataset_rf[' Label']\n",
        "\n",
        "model_rf = RandomForestClassifier()\n",
        "model_rf.fit(X_svm_rf, y_svm_rf)\n",
        "\n",
        "predictions_svm_rf = model_svm.predict(X_test_svm_rf)\n",
        "accuracy_svm_rf = accuracy_score(y_test_svm_rf, predictions_svm_rf)\n",
        "confusion_matrix_svm_rf = confusion_matrix(y_test_svm_rf, predictions_svm_rf)\n",
        "\n",
        "svm_params = model_svm.get_params()\n",
        "\n",
        "print(\"Iperparametri utilizzati nel modello SVM:\")\n",
        "for param, value in svm_params.items():\n",
        "    print(f\"{param}: {value}\")\n",
        "\n",
        "print(\"Accuratezza SVM RFC:\", accuracy_svm_rf)\n",
        "print(\"Matrice di Confusione SVM RFC:\\n\", confusion_matrix_svm_rf)\n",
        "\n",
        "class_report_svm_rf = classification_report(y_test_svm_rf, predictions_svm_rf)\n",
        "print(\"Classification Report - Random Forest RFC:\\n\", class_report_svm_rf)\n",
        "\n",
        "class_labels_svm_rf = model_svm.classes_\n",
        "\n",
        "for i, label in enumerate(class_labels_svm_rf):\n",
        "    fn = confusion_matrix_svm_rf[i, :].sum() - confusion_matrix_svm_rf[i, i]\n",
        "    fp = confusion_matrix_svm_rf[:, i].sum() - confusion_matrix_svm_rf[i, i]\n",
        "\n",
        "    print(f\"\\nClasse: {label}\")\n",
        "    print(f\"False Negative (FN): {fn}\")\n",
        "    print(f\"False Positive (FP): {fp}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AUIwoVgs954Y"
      },
      "outputs": [],
      "source": [
        "#SVM Test RFC\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
        "\n",
        "X_svm_rf = new_dataset_rf.drop(' Label', axis=1)\n",
        "y_svm_rf = new_dataset_rf[' Label']\n",
        "\n",
        "model_svm = SVC()\n",
        "model_svm.fit(X_svm_rf, y_svm_rf)\n",
        "\n",
        "predictions_svm_rf = model_svm.predict(X_svm_rf)\n",
        "accuracy_svm_rf = accuracy_score(y_svm_rf, predictions_svm_rf)\n",
        "confusion_matrix_svm_rf = confusion_matrix(y_svm_rf, predictions_svm_rf)\n",
        "precision_svm_rf = precision_score(y_svm_rf, predictions_svm_rf, average='weighted')\n",
        "recall_svm_rf = recall_score(y_svm_rf, predictions_svm_rf, average='weighted')\n",
        "f1_svm_rf = f1_score(y_svm_rf, predictions_svm_rf, average='weighted')\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(confusion_matrix_svm_rf, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "svm_params = model_svm.get_params()\n",
        "\n",
        "print(\"Iperparametri utilizzati nel modello SVM:\")\n",
        "for param, value in svm_params.items():\n",
        "    print(f\"{param}: {value}\")\n",
        "\n",
        "print(\"Accuratezza SVM RFC:\", accuracy_svm_rf)\n",
        "print(\"Precisione SVM RFC:\", precision_svm_rf)\n",
        "print(\"Richiamo SVM RFC:\", recall_svm_rf)\n",
        "print(\"F1-score SVM RFC:\", f1_svm_rf)\n",
        "\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "from sklearn.metrics import log_loss, roc_auc_score\n",
        "\n",
        "calibrated_svm = CalibratedClassifierCV(model_svm, method='sigmoid', cv='prefit')\n",
        "calibrated_svm.fit(X_svm_rf, y_svm_rf)\n",
        "\n",
        "predictions_proba_svm_rf = calibrated_svm.predict_proba(X_svm_rf)\n",
        "\n",
        "svm_log_loss = log_loss(y_svm_rf, predictions_proba_svm_rf)\n",
        "\n",
        "svm_roc_auc = roc_auc_score(y_svm_rf, predictions_proba_svm_rf, average='weighted', multi_class='ovr')\n",
        "\n",
        "print(\"Log-loss SVM RFC:\", svm_log_loss)\n",
        "print(\"ROC-AUC SVM RFC:\", svm_roc_auc)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9TfQehVtBV62"
      },
      "outputs": [],
      "source": [
        "!pip install boruta\n",
        "import pandas as pd\n",
        "from boruta import BorutaPy\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
        "\n",
        "X = dataset_subset[feature_cols]\n",
        "Y = dataset_subset[' Label']\n",
        "X_values = X.values\n",
        "Y_values = Y.values\n",
        "\n",
        "rf = RandomForestClassifier(n_jobs=-1, class_weight='balanced', max_depth=5)\n",
        "\n",
        "boruta_selector = BorutaPy(rf, n_estimators= 50 , verbose=0, max_iter = 100)\n",
        "\n",
        "np.int = np.int32\n",
        "np.float = np.float64\n",
        "np.bool = np.bool_\n",
        "\n",
        "boruta_selector.fit(X_values, Y_values)\n",
        "\n",
        "selected_features = X.columns[boruta_selector.support_]\n",
        "ranks = boruta_selector.ranking_\n",
        "\n",
        "print(\"Dimensione di selected_features:\", len(selected_features))\n",
        "print(\"Dimensione di boruta_selector.ranking_:\", len(ranks))\n",
        "print(\"Selected Features:\", selected_features[:50])\n",
        "print(\"Ranks:\", boruta_selector.ranking_[:50])\n",
        "\n",
        "X_selected = X[selected_features]\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X_selected, Y, test_size=None, random_state=42, stratify = Y)\n",
        "\n",
        "rf_selected_features = RandomForestClassifier(n_jobs=-1, class_weight='balanced', max_depth=5)\n",
        "\n",
        "rf_selected_features.fit(X.values, Y.values)\n",
        "\n",
        "Y_pred = rf_selected_features.predict(X.values)\n",
        "\n",
        "feature_importances = rf_selected_features.feature_importances_\n",
        "\n",
        "feature_weights = {feature: importance for feature, importance in zip(selected_features, feature_importances)}\n",
        "\n",
        "sorted_features = sorted(feature_weights, key=feature_weights.get, reverse=True)\n",
        "\n",
        "weights_boruta = {feature: weight for feature, weight in zip(sorted_features, range(1, len(sorted_features) + 1))}\n",
        "\n",
        "boruta_results = pd.DataFrame({'Feature': selected_features[:25], 'Rank': boruta_selector.ranking_[:25]})\n",
        "boruta_results = boruta_results.sort_values(by='Rank', ascending=True)\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.bar(range(len(boruta_results)), boruta_results['Rank'], tick_label=boruta_results['Feature'], color = 'skyblue')\n",
        "plt.xticks(rotation=90)\n",
        "plt.title('Boruta')\n",
        "plt.xlabel('Caratteristiche')\n",
        "plt.ylabel('Rango')\n",
        "plt.show()\n",
        "\n",
        "print(boruta_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "83Y16f7IIp8R"
      },
      "outputs": [],
      "source": [
        "# Seleziona le prime 10/20/30 feature da Boruta\n",
        "top_features_boruta = boruta_results['Feature'][-30:][::-1].tolist()\n",
        "\n",
        "selected_features_boruta = [' Label'] + top_features_boruta\n",
        "\n",
        "new_dataset_boruta = dataset_subset[selected_features_boruta]\n",
        "\n",
        "print(new_dataset_boruta.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EKF1bEx8XZ2o"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.experimental import enable_halving_search_cv\n",
        "from sklearn.model_selection import HalvingGridSearchCV\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "X_boruta = new_dataset_boruta.drop(' Label', axis=1)\n",
        "y_boruta = new_dataset_boruta[' Label']\n",
        "\n",
        "X_train_boruta, X_test_boruta, y_train_boruta, y_test_boruta = train_test_split(X_boruta, y_boruta, test_size=None, random_state=42)\n",
        "\n",
        "model_boruta = RandomForestClassifier()\n",
        "\n",
        "param_grid = {\"max_depth\": [3, None], \"min_samples_split\": [5, 10]}\n",
        "\n",
        "# Ricerca dei parametri migliori con Halving Grid Search CV\n",
        "search = HalvingGridSearchCV(model_boruta, param_grid, random_state=42).fit(X_boruta, y_boruta)\n",
        "best_boruta_params = search.best_params_\n",
        "\n",
        "print(\"Migliori parametri per RandomForestClassifier:\", best_boruta_params)\n",
        "\n",
        "best_model_boruta = RandomForestClassifier(**best_boruta_params)\n",
        "best_model_boruta.fit(X_boruta, y_boruta)\n",
        "\n",
        "predictions_boruta_best = best_model_boruta.predict(X_boruta)\n",
        "accuracy_boruta_best = accuracy_score(y_boruta, predictions_boruta_best)\n",
        "confusion_matrix_boruta_best = confusion_matrix(y_boruta, predictions_boruta_best)\n",
        "precision_boruta_best = precision_score(y_boruta, predictions_boruta_best, average='weighted')\n",
        "recall_boruta_best = recall_score(y_boruta, predictions_boruta_best, average='weighted')\n",
        "f1_boruta_best = f1_score(y_boruta, predictions_boruta_best, average='weighted')\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(confusion_matrix_boruta_best, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "print(\"Accuratezza RandomForest Boruta con i migliori parametri:\", accuracy_boruta_best)\n",
        "print(\"Precisione RandomForest RFC:\", precision_boruta_best)\n",
        "print(\"Recall RandomForest RFC:\", recall_boruta_best)\n",
        "print(\"F1-score RandomForest RFC:\", f1_boruta_best)\n",
        "\n",
        "from sklearn.metrics import log_loss, roc_auc_score\n",
        "\n",
        "probabilities_boruta_best = best_model_boruta.predict_proba(X_boruta)\n",
        "\n",
        "logloss_boruta_best = log_loss(y_boruta, probabilities_boruta_best)\n",
        "print(\"Log-loss RandomForest Boruta con i migliori parametri:\", logloss_boruta_best)\n",
        "\n",
        "roc_auc_boruta_best = roc_auc_score(y_boruta, probabilities_boruta_best, multi_class='ovr')\n",
        "print(\"Area sotto la curva ROC RandomForest Boruta con i migliori parametri:\", roc_auc_boruta_best)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.experimental import enable_halving_search_cv\n",
        "from sklearn.model_selection import HalvingGridSearchCV\n",
        "\n",
        "X_svm_b = new_dataset_boruta.drop(' Label', axis=1)\n",
        "y_svm_b = new_dataset_boruta[' Label']\n",
        "\n",
        "X_train_svm_b, X_test_svm_b, y_train_svm_b, y_test_svm_b = train_test_split(X_svm_b, y_svm_b, test_size=None, random_state=42)\n",
        "\n",
        "model_svm_b = SVC()\n",
        "\n",
        "param_grid = {'C': [0.5], 'kernel': ['rbf'], 'tol': [0.001]}\n",
        "\n",
        "search_svm = HalvingGridSearchCV(model_svm_b, param_grid, cv=5, factor=2, max_resources=110, min_resources=10, aggressive_elimination=False, random_state = 42)\n",
        "search_svm.fit(X_svm_b, y_svm_b)\n",
        "\n",
        "best_svm_params = search_svm.best_params_\n",
        "\n",
        "print(\"Migliori parametri per SVM:\", best_svm_params)\n",
        "\n",
        "best_model_svm_b = SVC(**best_svm_params, probability = True)\n",
        "best_model_svm_b.fit(X_svm_b, y_svm_b)\n",
        "\n",
        "predictions_svm_b = best_model_svm_b.predict(X_svm_b)\n",
        "accuracy_svm_b = accuracy_score(y_svm_b, predictions_svm_b)\n",
        "confusion_matrix_svm_b = confusion_matrix(y_svm_b, predictions_svm_b)\n",
        "precision_svm_b = precision_score(y_svm_b, predictions_svm_b, average='weighted')\n",
        "recall_svm_b = recall_score(y_svm_b, predictions_svm_b, average='weighted')\n",
        "f1_svm_b = f1_score(y_svm_b, predictions_svm_b, average='weighted')\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(confusion_matrix_svm_b, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "print(\"Accuratezza SVM Boruta con i migliori parametri:\", accuracy_svm_b)\n",
        "print(\"Precisione RandomForest RFC:\", precision_svm_b)\n",
        "print(\"Recall RandomForest RFC:\", recall_svm_b)\n",
        "print(\"F1-score RandomForest RFC:\", f1_svm_b)\n",
        "\n",
        "from sklearn.metrics import log_loss, roc_auc_score\n",
        "\n",
        "probabilities_svm_b = best_model_svm_b.predict_proba(X_svm_b)\n",
        "\n",
        "logloss_svm_b = log_loss(y_svm_b, probabilities_svm_b)\n",
        "print(\"Log-loss SVM Boruta con i migliori parametri:\", logloss_svm_b)\n",
        "\n",
        "roc_auc_svm_b = roc_auc_score(y_svm_b, probabilities_svm_b, multi_class='ovr')\n",
        "print(\"Area sotto la curva ROC SVM Boruta con i migliori parametri:\", roc_auc_svm_b)\n"
      ],
      "metadata": {
        "id": "DJ5jkm9EV2cS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T37wpOPpKk2v"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "X_boruta = new_dataset_boruta.drop(' Label', axis=1)\n",
        "y_boruta = new_dataset_boruta[' Label']\n",
        "\n",
        "X_train_boruta, X_test_boruta, y_train_boruta, y_test_boruta = train_test_split(X_boruta, y_boruta, test_size=None, random_state=42)\n",
        "\n",
        "model_boruta = RandomForestClassifier()\n",
        "model_boruta.fit(X_boruta, y_boruta)\n",
        "\n",
        "predictions_boruta = model_boruta.predict(X_boruta)\n",
        "accuracy_boruta = accuracy_score(y_boruta, predictions_boruta)\n",
        "confusion_matrix_boruta = confusion_matrix(y_boruta, predictions_boruta)\n",
        "precision_boruta = precision_score(y_boruta, predictions_boruta, average='weighted')\n",
        "recall_boruta = recall_score(y_boruta, predictions_boruta, average='weighted')\n",
        "f1_boruta = f1_score(y_boruta, predictions_boruta, average='weighted')\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(confusion_matrix_boruta, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "print(\"Accuratezza RandomForest Boruta:\", accuracy_boruta)\n",
        "print(\"Precisione RandomForest RFC:\", precision_boruta)\n",
        "print(\"Recall RandomForest RFC:\", recall_boruta)\n",
        "print(\"F1-score RandomForest RFC:\", f1_boruta)\n",
        "\n",
        "from sklearn.metrics import log_loss, roc_auc_score\n",
        "\n",
        "probabilities_boruta = model_boruta.predict_proba(X_boruta)\n",
        "\n",
        "logloss_boruta = log_loss(y_boruta, probabilities_boruta)\n",
        "\n",
        "roc_auc_boruta = roc_auc_score(y_boruta, probabilities_boruta, multi_class='ovr')\n",
        "\n",
        "print(\"Log-loss RandomForest Boruta:\", logloss_boruta)\n",
        "print(\"ROC-AUC RandomForest Boruta:\", roc_auc_boruta)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "StvnAIGA0xub"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "X_boruta = new_dataset_boruta.drop(' Label', axis=1)\n",
        "y_boruta = new_dataset_boruta[' Label']\n",
        "\n",
        "X_train_boruta, X_test_boruta, y_train_boruta, y_test_boruta = train_test_split(X_boruta, y_boruta, test_size=0.2, random_state=42)\n",
        "\n",
        "model_boruta = RandomForestClassifier()\n",
        "model_boruta.fit(X_train_boruta, y_train_boruta)\n",
        "\n",
        "predictions_boruta = model_boruta.predict(X_test_boruta)\n",
        "accuracy_boruta = accuracy_score(y_test_boruta, predictions_boruta)\n",
        "confusion_matrix_boruta = confusion_matrix(y_test_boruta, predictions_boruta)\n",
        "\n",
        "print(\"Accuratezza RandomForest Boruta:\", accuracy_boruta)\n",
        "print(\"Matrice di confusione RandomForest Boruta:\\n\", confusion_matrix_boruta)\n",
        "\n",
        "class_report_b_rf = classification_report(y_test_boruta, predictions_boruta)\n",
        "print(\"Classification Report - Random Forest RFC:\\n\", class_report_b_rf)\n",
        "\n",
        "class_labels_b_rf = model_boruta.classes_\n",
        "\n",
        "for i, label in enumerate(class_labels_b_rf):\n",
        "    fn = confusion_matrix_boruta[i, :].sum() - confusion_matrix_boruta[i, i]\n",
        "    fp = confusion_matrix_boruta[:, i].sum() - confusion_matrix_boruta[i, i]\n",
        "\n",
        "    print(f\"\\nClasse: {label}\")\n",
        "    print(f\"False Negative (FN): {fn}\")\n",
        "    print(f\"False Positive (FP): {fp}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3hUeREpS1oQE"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "X_svm_b = new_dataset_boruta.drop(' Label', axis=1)\n",
        "y_svm_b = new_dataset_boruta[' Label']\n",
        "\n",
        "X_train_svm_b, X_test_svm_b, y_train_svm_b, y_test_svm_b = train_test_split(X_svm_b, y_svm_b, test_size=0.2, random_state=42)\n",
        "\n",
        "model_svm_b = SVC()\n",
        "model_svm_b.fit(X_train_svm_b, y_train_svm_b)\n",
        "\n",
        "predictions_svm_b = model_svm_b.predict(X_test_svm_b)\n",
        "accuracy_svm_b = accuracy_score(y_test_svm_b, predictions_svm_b)\n",
        "confusion_matrix_svm_b = confusion_matrix(y_test_svm_b, predictions_svm_b)\n",
        "\n",
        "print(\"Accuratezza SVM RFC:\", accuracy_svm_b)\n",
        "print(\"Matrice di Confusione SVM RFC:\\n\", confusion_matrix_svm_b)\n",
        "\n",
        "class_report_svm_b = classification_report(y_test_svm_b, predictions_svm_b)\n",
        "print(\"Classification Report - Random Forest RFC:\\n\", class_report_svm_b)\n",
        "\n",
        "class_labels_svm_b = model_svm_b.classes_\n",
        "\n",
        "for i, label in enumerate(class_labels_b_rf):\n",
        "    fn = confusion_matrix_svm_b[i, :].sum() - confusion_matrix_svm_b[i, i]\n",
        "    fp = confusion_matrix_svm_b[:, i].sum() - confusion_matrix_svm_b[i, i]\n",
        "\n",
        "    print(f\"\\nClasse: {label}\")\n",
        "    print(f\"False Negative (FN): {fn}\")\n",
        "    print(f\"False Positive (FP): {fp}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wk8l5kQJMYM-"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "X_svm_b = new_dataset_boruta.drop(' Label', axis=1)\n",
        "y_svm_b = new_dataset_boruta[' Label']\n",
        "\n",
        "X_train_svm_b, X_test_svm_b, y_train_svm_b, y_test_svm_b = train_test_split(X_svm_b, y_svm_b, test_size=None, random_state=42)\n",
        "\n",
        "model_svm_b = SVC()\n",
        "model_svm_b.fit(X_svm_b, y_svm_b)\n",
        "\n",
        "predictions_svm_b = model_svm_b.predict(X_svm_b)\n",
        "accuracy_svm_b = accuracy_score(y_svm_b, predictions_svm_b)\n",
        "confusion_matrix_svm_b = confusion_matrix(y_svm_b, predictions_svm_b)\n",
        "precision_svm_b = precision_score(y_svm_b, predictions_svm_b, average='weighted')\n",
        "recall_svm_b = recall_score(y_svm_b, predictions_svm_b, average='weighted')\n",
        "f1_svm_b = f1_score(y_svm_b, predictions_svm_b, average='weighted')\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(confusion_matrix_svm_b, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "print(\"Accuratezza SVM RFC:\", accuracy_svm_b)\n",
        "print(\"Precisione RandomForest RFC:\", precision_svm_b)\n",
        "print(\"Recall RandomForest RFC:\", recall_svm_b)\n",
        "print(\"F1-score RandomForest RFC:\", f1_svm_b)\n",
        "\n",
        "from sklearn.metrics import log_loss, roc_auc_score\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "\n",
        "decision_function_svm_b = model_svm_b.decision_function(X_svm_b)\n",
        "\n",
        "label_binarizer = LabelBinarizer()\n",
        "label_binarizer.fit(y_svm_b)\n",
        "y_test_svm_b_bin = label_binarizer.transform(y_svm_b)\n",
        "\n",
        "probabilities_svm_b = (decision_function_svm_b - decision_function_svm_b.min()) / (decision_function_svm_b.max() - decision_function_svm_b.min())\n",
        "\n",
        "logloss_svm_b = log_loss(y_test_svm_b_bin, probabilities_svm_b)\n",
        "\n",
        "roc_auc_svm_b = roc_auc_score(y_test_svm_b_bin, probabilities_svm_b, average='weighted')\n",
        "\n",
        "print(\"Log-loss SVM Boruta:\", logloss_svm_b)\n",
        "print(\"ROC-AUC SVM Boruta:\", roc_auc_svm_b)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FrZnXhT-GQ-6"
      },
      "outputs": [],
      "source": [
        "pca = PCA(n_components=50)\n",
        "pca_res = pca.fit_transform(dataset_subset[feature_cols])\n",
        "\n",
        "loadings = np.abs(pca.components_[0])\n",
        "\n",
        "top_variables_indices = np.argsort(loadings)[::-1]\n",
        "\n",
        "N = 50\n",
        "top_variables = top_variables_indices[:N]\n",
        "\n",
        "column_names = dataset_subset.columns\n",
        "\n",
        "top_variable_names = [column_names[idx] for idx in top_variables]\n",
        "top_variable_loadings = [loadings[idx] for idx in top_variables]\n",
        "\n",
        "weights_pca = {column_names[idx]: weight for weight, idx in enumerate(top_variables_indices, start=1)}\n",
        "\n",
        "plt.figure(figsize=(12,8))\n",
        "plt.bar(top_variable_names, top_variable_loadings, color='skyblue')\n",
        "plt.xlabel('Carichi delle Variabili')\n",
        "plt.title('Carichi delle Variabili più Influenti dopo PCA')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.show()\n",
        "\n",
        "total_variance = np.sum(np.var(dataset_subset, axis=0))\n",
        "explained_variance = np.sum(pca.explained_variance_[:N])\n",
        "accuracy_pca = (explained_variance/total_variance)*100\n",
        "\n",
        "for idx in top_variables:\n",
        "    variable_name = column_names[idx]\n",
        "    print(f\"Variabile: {variable_name}, Carico: {loadings[idx]}\")\n",
        "\n",
        "print(accuracy_pca)\n",
        "\n",
        "data_subset = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E1NrNWlfaEUR"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.experimental import enable_halving_search_cv\n",
        "from sklearn.model_selection import HalvingGridSearchCV\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
        "\n",
        "features = dataset_subset.drop(' Label', axis=1)\n",
        "target = dataset_subset[' Label']\n",
        "X_train_pca, X_test_pca, y_train_pca, y_test_pca = train_test_split(pca_res[:, :30], target, test_size=None, random_state=42)\n",
        "\n",
        "model_pca_rf = RandomForestClassifier()\n",
        "\n",
        "param_grid = {\"max_depth\": [3, None], \"min_samples_split\": [5, 10]}\n",
        "\n",
        "# Ricerca dei parametri migliori con Halving Grid Search CV\n",
        "search = HalvingGridSearchCV(model_pca_rf, param_grid, random_state=42).fit(features, target)\n",
        "best_pca_params = search.best_params_\n",
        "\n",
        "print(\"Migliori parametri per RandomForestClassifier:\", best_pca_params)\n",
        "\n",
        "best_model_pca = RandomForestClassifier(**best_pca_params)\n",
        "best_model_pca.fit(features, target)\n",
        "\n",
        "predictions_pca_best = best_model_pca.predict(features)\n",
        "accuracy_pca_best = accuracy_score(target, predictions_pca_best)\n",
        "confusion_matrix_pca_best = confusion_matrix(target, predictions_pca_best)\n",
        "precision_pca_best = precision_score(target, predictions_pca_best, average='weighted')\n",
        "recall_pca_best = recall_score(target, predictions_pca_best, average='weighted')\n",
        "f1_score_pca_best = f1_score(target, predictions_pca_best, average='weighted')\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(confusion_matrix_pca_best, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "print(\"Accuratezza RandomForest PCA con i migliori parametri:\", accuracy_pca_best)\n",
        "print(\"Precisione RandomForest PCA con i migliori parametri:\", precision_pca_best)\n",
        "print(\"Recall RandomForest PCA con i migliori parametri:\", recall_pca_best)\n",
        "print(\"F1-score RandomForest PCA con i migliori parametri:\", f1_score_pca_best)\n",
        "\n",
        "from sklearn.metrics import log_loss, roc_auc_score\n",
        "\n",
        "probabilities_pca_best = best_model_pca.predict_proba(features)\n",
        "\n",
        "log_loss_pca_best = log_loss(target, probabilities_pca_best)\n",
        "\n",
        "roc_auc_pca_best = roc_auc_score(target, probabilities_pca_best, multi_class='ovr', average='weighted')\n",
        "\n",
        "print(\"Log-loss RandomForest PCA con i migliori parametri:\", log_loss_pca_best)\n",
        "print(\"ROC-AUC RandomForest PCA con i migliori parametri:\", roc_auc_pca_best)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UWC9sC5pbEi4"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
        "from sklearn.metrics import log_loss, roc_auc_score\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "\n",
        "features = dataset_subset.drop(' Label', axis=1)\n",
        "target = dataset_subset[' Label']\n",
        "X_train_svm_pca, X_test_svm_pca, y_train_svm_pca, y_test_svm_pca = train_test_split(pca_res[:, :30], target, test_size=None, random_state=42)\n",
        "\n",
        "svm_model_pca = SVC()\n",
        "\n",
        "param_grid = {'C': [0.1, 0.5, 1, 2, 5, 10], 'kernel': ['linear', 'rbf', 'sigmoid', 'poly'], 'tol': [1e-3, 1e-2]}\n",
        "\n",
        "search_svm = HalvingGridSearchCV(svm_model_pca, param_grid, cv=5, factor=2, max_resources=110, min_resources=10, aggressive_elimination=False, random_state=42)\n",
        "search_svm.fit(features, target)\n",
        "\n",
        "best_svm_params = search_svm.best_params_\n",
        "\n",
        "print(\"Migliori parametri per SVM:\", best_svm_params)\n",
        "\n",
        "best_model_svm_pca = SVC(**best_svm_params)\n",
        "best_model_svm_pca.fit(features, target)\n",
        "\n",
        "predictions_svm_pca = best_model_svm_pca.predict(features)\n",
        "accuracy_svm_pca = accuracy_score(target, predictions_svm_pca)\n",
        "confusion_matrix_svm_pca = confusion_matrix(target, predictions_svm_pca)\n",
        "precision_svm_pca = precision_score(target, predictions_svm_pca, average='weighted')\n",
        "recall_svm_pca = recall_score(target, predictions_svm_pca, average='weighted')\n",
        "f1_score_svm_pca = f1_score(target, predictions_svm_pca, average='weighted')\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(confusion_matrix_svm_pca, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "print(\"Accuratezza SVM PCA con i migliori parametri:\", accuracy_svm_pca)\n",
        "print(\"Precisione SVM PCA con i migliori parametri:\", precision_svm_pca)\n",
        "print(\"Recall SVM PCA con i migliori parametri:\", recall_svm_pca)\n",
        "print(\"F1-score SVM PCA con i migliori parametri:\", f1_score_svm_pca)\n",
        "\n",
        "svm_model_ovr = OneVsRestClassifier(SVC(**best_svm_params, probability=True))\n",
        "svm_model_ovr.fit(features, target)\n",
        "\n",
        "svm_probabilities_ovr = svm_model_ovr.predict_proba(features)\n",
        "\n",
        "logloss_svm_pca = log_loss(target, svm_probabilities_ovr)\n",
        "\n",
        "y_test_svm_pca_binarized = label_binarize(target, classes=svm_model_ovr.classes_)\n",
        "\n",
        "roc_auc_svm_pca = roc_auc_score(y_test_svm_pca_binarized, svm_probabilities_ovr, average='weighted')\n",
        "\n",
        "print(\"Log-loss per SVM PCA:\", logloss_svm_pca)\n",
        "print(\"Area sotto la curva ROC (ROC-AUC) per SVM PCA:\", roc_auc_svm_pca)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0V7-EriAOq7l"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
        "\n",
        "features = dataset_subset.drop(' Label', axis=1)\n",
        "target = dataset_subset[' Label']\n",
        "X_train_pca, X_test_pca, y_train_pca, y_test_pca = train_test_split(pca_res[:, :30], target, test_size=None, random_state=42)\n",
        "\n",
        "rf_model_pca = RandomForestClassifier()\n",
        "rf_model_pca.fit(features, target)\n",
        "rf_predictions_pca = rf_model_pca.predict(features)\n",
        "\n",
        "rf_accuracy_pca = accuracy_score(target, rf_predictions_pca)\n",
        "precision_rf_pca = precision_score(target, rf_predictions_pca, average='weighted')\n",
        "recall_rf_pca = recall_score(target, rf_predictions_pca, average='weighted')\n",
        "f1_score_rf_pca = f1_score(target, rf_predictions_pca, average='weighted')\n",
        "print(\"Accuracy Random Forest:\", rf_accuracy_pca)\n",
        "\n",
        "rf_conf_matrix_pca = confusion_matrix(target, rf_predictions_pca)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(rf_conf_matrix_pca, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "print(\"Precisione Random Forest con PCA:\", precision_rf_pca)\n",
        "print(\"Recall Random Forest con PCA:\", recall_rf_pca)\n",
        "print(\"F1-score Random Forest con PCA:\", f1_score_rf_pca)\n",
        "\n",
        "from sklearn.metrics import log_loss, roc_auc_score\n",
        "\n",
        "rf_probabilities_pca = rf_model_pca.predict_proba(features)\n",
        "\n",
        "log_loss_rf_pca = log_loss(target, rf_probabilities_pca, labels=rf_model_pca.classes_)\n",
        "\n",
        "roc_auc_rf_pca = roc_auc_score(target, rf_probabilities_pca, average='weighted', multi_class='ovr')\n",
        "\n",
        "print(\"Log-loss Random Forest con PCA:\", log_loss_rf_pca)\n",
        "print(\"ROC-AUC Random Forest con PCA:\", roc_auc_rf_pca)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pbwx0SfR2noH"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.experimental import enable_halving_search_cv\n",
        "from sklearn.model_selection import HalvingGridSearchCV\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "target = dataset_subset[' Label']\n",
        "X_train_pca, X_test_pca, y_train_pca, y_test_pca = train_test_split(pca_res[:, :20], target, test_size=0.2, random_state=42)\n",
        "\n",
        "model_pca_rf = RandomForestClassifier()\n",
        "\n",
        "param_grid = {\"max_depth\": [3, None], \"min_samples_split\": [5, 10]}\n",
        "\n",
        "search = HalvingGridSearchCV(model_pca_rf, param_grid, random_state=42).fit(X_train_pca, y_train_pca)\n",
        "best_pca_params = search.best_params_\n",
        "\n",
        "print(\"Migliori parametri per RandomForestClassifier:\", best_pca_params)\n",
        "\n",
        "best_model_pca = RandomForestClassifier(**best_pca_params)\n",
        "best_model_pca.fit(X_train_pca, y_train_pca)\n",
        "\n",
        "predictions_pca_best = best_model_pca.predict(X_test_pca)\n",
        "accuracy_pca_best = accuracy_score(y_test_pca, predictions_pca_best)\n",
        "confusion_matrix_pca_best = confusion_matrix(y_test_pca, predictions_pca_best)\n",
        "\n",
        "print(\"Accuratezza RandomForest PCA con i migliori parametri:\", accuracy_pca_best)\n",
        "print(\"Matrice di confusione RandomForest PCA con i migliori parametri:\\n\", confusion_matrix_pca_best)\n",
        "\n",
        "class_report_pca = classification_report(y_test_pca, predictions_pca_best)\n",
        "print(\"Classification Report - Random Forest RFC:\\n\", class_report_pca)\n",
        "\n",
        "class_labels_pca = best_model_pca.classes_\n",
        "\n",
        "for i, label in enumerate(class_labels_pca):\n",
        "    fn = confusion_matrix_pca_best[i, :].sum() - confusion_matrix_pca_best[i, i]\n",
        "    fp = confusion_matrix_pca_best[:, i].sum() - confusion_matrix_pca_best[i, i]\n",
        "\n",
        "    print(f\"\\nClasse: {label}\")\n",
        "    print(f\"False Negative (FN): {fn}\")\n",
        "    print(f\"False Positive (FP): {fp}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1paQi4Ys3pGg"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.experimental import enable_halving_search_cv\n",
        "from sklearn.model_selection import HalvingGridSearchCV\n",
        "\n",
        "target = dataset_subset[' Label']\n",
        "X_train_svm_pca, X_test_svm_pca, y_train_svm_pca, y_test_svm_pca = train_test_split(pca_res[:, :10], target, test_size=0.2, random_state=42)\n",
        "\n",
        "svm_model_pca = SVC()\n",
        "\n",
        "param_grid = {'C': [0.1, 0.5, 1, 2, 5, 10], 'kernel': ['linear', 'rbf', 'sigmoid', 'poly'], 'tol': [1e-3, 1e-2]}\n",
        "\n",
        "search_svm = HalvingGridSearchCV(svm_model_pca, param_grid, cv=5, factor=2, max_resources=110, min_resources=10, aggressive_elimination=False, random_state = 42)\n",
        "search_svm.fit(X_train_svm_pca, y_train_svm_pca)\n",
        "\n",
        "best_svm_params = search_svm.best_params_\n",
        "\n",
        "print(\"Migliori parametri per SVM:\", best_svm_params)\n",
        "\n",
        "best_model_svm_pca = SVC(**best_svm_params)\n",
        "best_model_svm_pca.fit(X_train_svm_pca, y_train_svm_pca)\n",
        "\n",
        "predictions_svm_pca = best_model_svm_pca.predict(X_test_svm_pca)\n",
        "accuracy_svm_pca = accuracy_score(y_test_svm_pca, predictions_svm_pca)\n",
        "confusion_matrix_svm_pca = confusion_matrix(y_test_svm_pca, predictions_svm_pca)\n",
        "\n",
        "print(\"Accuratezza SVM PCA con i migliori parametri:\", accuracy_svm_pca)\n",
        "print(\"Matrice di confusione SVM PCA con i migliori parametri:\\n\", confusion_matrix_svm_pca)\n",
        "\n",
        "class_report_svm_pca = classification_report(y_test_svm_pca, predictions_svm_pca)\n",
        "print(\"Classification Report - Random Forest RFC:\\n\", class_report_svm_pca)\n",
        "\n",
        "class_labels_svm_pca = best_model_svm_pca.classes_\n",
        "\n",
        "for i, label in enumerate(class_labels_svm_pca):\n",
        "    fn = confusion_matrix_svm_pca[i, :].sum() - confusion_matrix_svm_pca[i, i]\n",
        "    fp = confusion_matrix_svm_pca[:, i].sum() - confusion_matrix_svm_pca[i, i]\n",
        "\n",
        "    print(f\"\\nClasse: {label}\")\n",
        "    print(f\"False Negative (FN): {fn}\")\n",
        "    print(f\"False Positive (FP): {fp}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0YDRq1jiTZWY"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "features = dataset_subset.drop(' Label', axis=1)\n",
        "target = dataset_subset[' Label']\n",
        "X_train_svm_pca, X_test_svm_pca, y_train_svm_pca, y_test_svm_pca = train_test_split(pca_res[:, :30], target, test_size=0.2, random_state=42)\n",
        "\n",
        "svm_model_pca = SVC()\n",
        "svm_model_pca.fit(features, target)\n",
        "svm_predictions_pca = svm_model_pca.predict(features)\n",
        "\n",
        "svm_accuracy_pca = accuracy_score(target, svm_predictions_pca)\n",
        "precision_svm_pca = precision_score(target, svm_predictions_pca, average='weighted')\n",
        "recall_svm_pca = recall_score(target, svm_predictions_pca, average='weighted')\n",
        "f1_score_svm_pca = f1_score(target, svm_predictions_pca, average='weighted')\n",
        "\n",
        "print(\"Accuratezza SVM PCA:\", svm_accuracy_pca)\n",
        "\n",
        "svm_conf_matrix_pca = confusion_matrix(target, svm_predictions_pca)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(svm_conf_matrix_pca, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "print(\"Precisione SVM PCA:\", precision_svm_pca)\n",
        "print(\"Recall SVM PCA:\", recall_svm_pca)\n",
        "print(\"F1-score SVM PCA:\", f1_score_svm_pca)\n",
        "\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "ovr_model = OneVsRestClassifier(SVC(probability=True))\n",
        "ovr_model.fit(features, target)\n",
        "\n",
        "svm_probabilities_pca = ovr_model.predict_proba(features)\n",
        "\n",
        "log_loss_svm_pca = log_loss(target, svm_probabilities_pca)\n",
        "\n",
        "roc_auc_svm_pca = roc_auc_score(target, svm_probabilities_pca, average='weighted', multi_class='ovr')\n",
        "\n",
        "print(\"Log-loss SVM PCA:\", log_loss_svm_pca)\n",
        "print(\"ROC-AUC SVM PCA:\", roc_auc_svm_pca)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JJPjL0UZzwF8"
      },
      "outputs": [],
      "source": [
        "total_accuracy = accuracy_pca + accuracy_boruta + accuracy_rf\n",
        "alpha_pca = accuracy_pca / total_accuracy\n",
        "alpha_boruta = accuracy_boruta / total_accuracy\n",
        "alpha_rf = accuracy_rf / total_accuracy\n",
        "\n",
        "combined_ranking = {}\n",
        "\n",
        "for feature in feature_df['Feature']:\n",
        "    borda_score_pca = weights_pca.get(feature, 0)\n",
        "    borda_score_boruta = weights_boruta.get(feature, 0)\n",
        "    borda_score_rf = weights_rf.get(feature, 0)\n",
        "\n",
        "    wborda_score_pca = weights_pca.get(feature, 0)\n",
        "    wborda_score_boruta = weights_boruta.get(feature, 0)\n",
        "    wborda_score_rf = weights_rf.get(feature, 0)\n",
        "\n",
        "    combined_score = (\n",
        "        alpha_pca * borda_score_pca + alpha_boruta * borda_score_boruta + alpha_rf * borda_score_rf +\n",
        "        alpha_pca * wborda_score_pca + alpha_boruta * wborda_score_boruta + alpha_rf * wborda_score_rf\n",
        "    )\n",
        "\n",
        "    combined_ranking[feature] = combined_score\n",
        "\n",
        "combined_ranking_sorted = {k: v for k, v in sorted(combined_ranking.items(), key=lambda item: item[1], reverse=True)}\n",
        "\n",
        "for feature, score in combined_ranking_sorted.items():\n",
        "    print(f\"Feature: {feature}, Punteggio Combinato: {score:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UY4VPmT0uT0N"
      },
      "outputs": [],
      "source": [
        "# Seleziona le prime 10/20/30 feature dal ranking combinato\n",
        "top_features_combined = list(combined_ranking_sorted.keys())[:20]\n",
        "\n",
        "selected_features_combined = [' Label'] + top_features_combined\n",
        "\n",
        "new_dataset_combined = dataset_subset[selected_features_combined]\n",
        "\n",
        "print(new_dataset_combined.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7acutl9zb4cC"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.experimental import enable_halving_search_cv\n",
        "from sklearn.model_selection import HalvingGridSearchCV\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "X_rf_combined = new_dataset_combined.drop(' Label', axis=1)\n",
        "y_rf_combined = new_dataset_combined[' Label']\n",
        "\n",
        "X_train_rf_combined, X_test_rf_combined, y_train_rf_combined, y_test_rf_combined = train_test_split(X_rf_combined, y_rf_combined, test_size=0.2, random_state=42)\n",
        "\n",
        "model_rf_combined = RandomForestClassifier()\n",
        "\n",
        "param_grid = {\"max_depth\": [3, None], \"min_samples_split\": [5, 10]}\n",
        "\n",
        "search = HalvingGridSearchCV(model_rf_combined, param_grid, random_state=42).fit(X_train_rf_combined, y_train_rf_combined)\n",
        "best_combined_params = search.best_params_\n",
        "\n",
        "print(\"Migliori parametri per RandomForest:\", best_combined_params)\n",
        "\n",
        "best_model_combined = RandomForestClassifier(**best_combined_params)\n",
        "best_model_combined.fit(X_train_rf_combined, y_train_rf_combined)\n",
        "\n",
        "predictions_combined_best = best_model_combined.predict(X_test_rf_combined)\n",
        "accuracy_combined_best = accuracy_score(y_test_rf_combined, predictions_combined_best)\n",
        "confusion_matrix_combined_best = confusion_matrix(y_test_rf_combined, predictions_combined_best)\n",
        "\n",
        "print(\"Accuratezza RandomForest R.combinato con i migliori parametri:\", accuracy_combined_best)\n",
        "print(\"Matrice di confusione RandomForest R.combinato con i migliori parametri:\\n\", confusion_matrix_combined_best)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "syWOr0z-b4Dq"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.experimental import enable_halving_search_cv\n",
        "from sklearn.model_selection import HalvingGridSearchCV\n",
        "\n",
        "X_svm_combined = new_dataset_combined.drop(' Label', axis=1)\n",
        "y_svm_combined = new_dataset_combined[' Label']\n",
        "\n",
        "X_train_svm_combined, X_test_svm_combined, y_train_svm_combined, y_test_svm_combined = train_test_split(X_svm_combined, y_svm_combined, test_size=0.2, random_state=42)\n",
        "\n",
        "model_svm_combined = SVC()\n",
        "\n",
        "param_grid = {'C': [0.1, 0.5, 1, 2, 5, 10], 'kernel': ['linear', 'rbf', 'sigmoid', 'poly'], 'tol': [1e-3, 1e-2]}\n",
        "\n",
        "search_svm = HalvingGridSearchCV(model_svm_combined, param_grid, cv=5, factor=2, max_resources=110, min_resources=10, aggressive_elimination=False, random_state = 42)\n",
        "search_svm.fit(X_train_svm_combined, y_train_svm_combined)\n",
        "\n",
        "best_svm_params = search_svm.best_params_\n",
        "\n",
        "print(\"Migliori parametri per SVM:\", best_svm_params)\n",
        "\n",
        "best_model_svm_combined = SVC(**best_svm_params)\n",
        "best_model_svm_combined.fit(X_train_svm_combined, y_train_svm_combined)\n",
        "\n",
        "predictions_svm_combined = best_model_svm_combined.predict(X_test_svm_combined)\n",
        "accuracy_svm_combined = accuracy_score(y_test_svm_combined, predictions_svm_combined)\n",
        "confusion_matrix_svm_combined = confusion_matrix(y_test_svm_combined, predictions_svm_combined)\n",
        "\n",
        "print(\"Accuratezza SVM R.combinato con i migliori parametri:\", accuracy_svm_combined)\n",
        "print(\"Matrice di confusione SVM R.combinato con i migliori parametri:\\n\", confusion_matrix_svm_combined)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zhwFeZBEui90"
      },
      "outputs": [],
      "source": [
        "#RF per ranking combinato\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "X_rf_combined = new_dataset_combined.drop(' Label', axis=1)\n",
        "y_rf_combined = new_dataset_combined[' Label']\n",
        "\n",
        "X_train_rf_combined, X_test_rf_combined, y_train_rf_combined, y_test_rf_combined = train_test_split(X_rf_combined, y_rf_combined, test_size=0.2, random_state=42)\n",
        "\n",
        "model_rf_combined = RandomForestClassifier()\n",
        "model_rf_combined.fit(X_train_rf_combined, y_train_rf_combined)\n",
        "\n",
        "predictions_rf_combined = model_rf_combined.predict(X_test_rf_combined)\n",
        "accuracy_rf_combined = accuracy_score(y_test_rf_combined, predictions_rf_combined)\n",
        "confusion_matrix_rf_combined = confusion_matrix(y_test_rf_combined, predictions_rf_combined)\n",
        "\n",
        "print(\"Accuratezza RandomForest Ranking Combinato:\", accuracy_rf_combined)\n",
        "print(\"Matrice Confusione RandomForest Ranking Combinato:\\n\", confusion_matrix_rf_combined)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "APBS3EAr4rz0"
      },
      "outputs": [],
      "source": [
        "#RF per ranking combinato\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "X_rf_combined = new_dataset_combined.drop(' Label', axis=1)\n",
        "y_rf_combined = new_dataset_combined[' Label']\n",
        "\n",
        "X_train_rf_combined, X_test_rf_combined, y_train_rf_combined, y_test_rf_combined = train_test_split(X_rf_combined, y_rf_combined, test_size=0.2, random_state=42)\n",
        "\n",
        "model_rf_combined = RandomForestClassifier()\n",
        "model_rf_combined.fit(X_train_rf_combined, y_train_rf_combined)\n",
        "\n",
        "predictions_rf_combined = model_rf_combined.predict(X_test_rf_combined)\n",
        "accuracy_rf_combined = accuracy_score(y_test_rf_combined, predictions_rf_combined)\n",
        "confusion_matrix_rf_combined = confusion_matrix(y_test_rf_combined, predictions_rf_combined)\n",
        "\n",
        "print(\"Accuratezza RandomForest Ranking Combinato:\", accuracy_rf_combined)\n",
        "print(\"Matrice Confusione RandomForest Ranking Combinato:\\n\", confusion_matrix_rf_combined)\n",
        "\n",
        "class_report_combined = classification_report(y_test_rf_combined, predictions_rf_combined)\n",
        "print(\"Classification Report - Random Forest RFC:\\n\", class_report_combined)\n",
        "\n",
        "class_labels_combined = model_rf_combined.classes_\n",
        "\n",
        "for i, label in enumerate(class_labels_combined):\n",
        "    fn = confusion_matrix_rf_combined[i, :].sum() - confusion_matrix_rf_combined[i, i]\n",
        "    fp = confusion_matrix_rf_combined[:, i].sum() - confusion_matrix_rf_combined[i, i]\n",
        "\n",
        "    print(f\"\\nClasse: {label}\")\n",
        "    print(f\"False Negative (FN): {fn}\")\n",
        "    print(f\"False Positive (FP): {fp}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oXJieBSj5Q6r"
      },
      "outputs": [],
      "source": [
        "#SVM per ranking combinato\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "X_svm_combined = new_dataset_combined.drop(' Label', axis=1)\n",
        "y_svm_combined = new_dataset_combined[' Label']\n",
        "\n",
        "X_train_svm_combined, X_test_svm_combined, y_train_svm_combined, y_test_svm_combined = train_test_split(X_svm_combined, y_svm_combined, test_size=0.2, random_state=42)\n",
        "\n",
        "model_svm_combined = SVC()\n",
        "model_svm_combined.fit(X_train_svm_combined, y_train_svm_combined)\n",
        "\n",
        "predictions_svm_combined = model_svm_combined.predict(X_test_svm_combined)\n",
        "accuracy_svm_combined = accuracy_score(y_test_svm_combined, predictions_svm_combined)\n",
        "confusion_matrix_svm_combined = confusion_matrix(y_test_svm_combined, predictions_svm_combined)\n",
        "\n",
        "print(\"Accuracy SVM (con le prime 20 feature):\", accuracy_svm_combined)\n",
        "print(\"Confusion Matrix SVM (con le prime 20 feature):\\n\", confusion_matrix_svm_combined)\n",
        "\n",
        "class_report_svm_combined = classification_report(y_test_svm_combined, predictions_svm_combined)\n",
        "print(\"Classification Report - Random Forest RFC:\\n\", class_report_svm_combined)\n",
        "\n",
        "class_labels_svm_combined = model_svm_combined.classes_\n",
        "\n",
        "for i, label in enumerate(class_labels_svm_combined):\n",
        "    fn = confusion_matrix_svm_combined[i, :].sum() - confusion_matrix_svm_combined[i, i]\n",
        "    fp = confusion_matrix_svm_combined[:, i].sum() - confusion_matrix_svm_combined[i, i]\n",
        "\n",
        "    print(f\"\\nClasse: {label}\")\n",
        "    print(f\"False Negative (FN): {fn}\")\n",
        "    print(f\"False Positive (FP): {fp}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E4dtxtpEvL79"
      },
      "outputs": [],
      "source": [
        "#SVM per ranking combinato\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "X_svm_combined = new_dataset_combined.drop(' Label', axis=1)\n",
        "y_svm_combined = new_dataset_combined[' Label']\n",
        "\n",
        "X_train_svm_combined, X_test_svm_combined, y_train_svm_combined, y_test_svm_combined = train_test_split(X_svm_combined, y_svm_combined, test_size=0.2, random_state=42)\n",
        "\n",
        "model_svm_combined = SVC()\n",
        "model_svm_combined.fit(X_train_svm_combined, y_train_svm_combined)\n",
        "\n",
        "predictions_svm_combined = model_svm_combined.predict(X_test_svm_combined)\n",
        "accuracy_svm_combined = accuracy_score(y_test_svm_combined, predictions_svm_combined)\n",
        "confusion_matrix_svm_combined = confusion_matrix(y_test_svm_combined, predictions_svm_combined)\n",
        "\n",
        "print(\"Accuracy SVM (con le prime 20 feature):\", accuracy_svm_combined)\n",
        "print(\"Confusion Matrix SVM (con le prime 20 feature):\\n\", confusion_matrix_svm_combined)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HAlqJXWQGQ8A"
      },
      "outputs": [],
      "source": [
        "tsne = TSNE(n_components=2, verbose=0, perplexity=100, n_iter=1000)\n",
        "tsne_res = tsne.fit_transform(pca_res)\n",
        "print(\"done\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Go0j1ixTHFSY"
      },
      "outputs": [],
      "source": [
        "dataset_subset['tsne_firstD'] = tsne_res[:,0]\n",
        "dataset_subset['tsne_secondD'] = tsne_res[:,1]\n",
        "dataset_subset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6-_EKfj6gNRH"
      },
      "outputs": [],
      "source": [
        "custom_palette = [\n",
        "    (0, 0, 0),       # Nero\n",
        "    (1, 1, 0),       # Giallo\n",
        "    (1, 0, 0),       # Rosso\n",
        "    (0, 1, 0),       # Verde\n",
        "    (1, 0.549, 0),   # Arancione\n",
        "    (1, 0, 1),       # Fuchsia\n",
        "    (0, 1, 1),       # Ciano\n",
        "    (0, 0, 1),       # Blu\n",
        "    (0.502, 0, 0.502),  # Lilla\n",
        "    (0.502, 0.502, 0),  # Olive\n",
        "    (0, 0.749, 1)   # Turchese\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mfq8RCFcHFKf"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(16,16))\n",
        "\n",
        "sns.scatterplot(\n",
        "    x=\"tsne_firstD\",\n",
        "    y=\"tsne_secondD\",\n",
        "    palette=custom_palette,\n",
        "    data=dataset_subset,\n",
        "    hue=' Label',\n",
        "    legend=\"full\",\n",
        "    alpha=0.75\n",
        ")\n",
        "\n",
        "plt.xlabel('tsne_firstD')\n",
        "plt.ylabel('tsne_secondD')\n",
        "plt.title('Anomaly Detection')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1cDtynI638ennqI7o74wj0VNoOdR2rpsZ",
      "authorship_tag": "ABX9TyMWSqaz0A9Um3A7l7b/ybzT",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}